[DEFAULT]
geom_sqr : 512x512      
geom_wide : 896x512


[binning.dmcopy.sky.size]
title : Bin Event File to Image; Specify Bin Size
requires: acisf06934N002_evt2.fits
provides: 6934_sky_binsize.fits
commands: dmcopy "%(requires)s[bin x=3500:4500:2,y=3500:4500:2]" %(provides)s clob+
outfile : 6934_sky_binsize.fits
ds9_extras : -scale log -geometry %(geom_sqr)s -zoom 1 -cmap load $ASCDS_CONTRIB/data/heart.lut
pretext : <p>
    One of the first things Chandra users want to do is to bin their
    event file into an image.  The <tt>ds9</tt> application does this
    automatically when you load the event file; but when you need to 
    run tools such as <ahelp name="wavdetect" tt="1"/> or <ahelp name="csmooth" tt="1"/>
    you will need to bin the event file into an image yourself using <tt>dmcopy</tt>.
    </p>

posttest : <p>This is a simple example showing the <tt>[bin ]</tt> syntax 
    where the <tt>X</tt> and <tt>Y</tt> columns are binned independently
    using the <tt>min:max:stepsize</tt> syntax.
    </p>
 

[binning.dmcopy.sky.nbin]
title : Bin Event File to Image; Specify Number of Bins
requires : acisf06934N002_evt2.fits
provides : 6934_sky_nbins.fits
commands: dmcopy "%(requires)s[bin x=3500:4500:#512,y=3500:4500:#512]" %(provides)s clob+
outfile : %(provides)s
ds9_extras : -scale log -geometry %(geom_sqr)s -zoom 1 -cmap load $ASCDS_CONTRIB/data/heart.lut
pretext: <p>Rather than specify bin size you can specify number of bins.</p>
posttext : <p>This example produces the same output as 
    <cxclink href="#binning.dmcopy.sky.size">the
    example above</cxclink>, but rather than specifying the bin size we
    specify the number of bins. 
    </p>
## TODO: subpixel, non-integer

[binning.dmcopy.sky.filt]
requires : acisf06934N002_evt2.fits
provides : 6934_sky_circle.fits
title : Bin Event File to Image With Filtering
commands : dmcopy "%(requires)s[sky=circle(4096.5,4096.5,500)][bin sky=2]" %(provides)s clob+
outfile : %(provides)s
ds9_extras : -scale log -geometry %(geom_sqr)s -zoom 1 -cmap load $ASCDS_CONTRIB/data/heart.lut
pretext : <p>
    Typically, users will also need to apply various filters to their datasets
    when they are binning.  In this example we apply a circular spatial filter to the
    event file as the data are being binned.  
    </p>
posttext : 
    <p>
    In this example, the individual columns X and Y ranges have been replaced 
    with the simplified syntax <tt>[bin sky=2]</tt>.  <tt>sky</tt> is the
    name of the <em>vector column</em>, composed of the X and Y columns.
    </p>
    <p>By default the image shrinks to a bounding-box around the filter.  
    Values outside the
    region are set to 0.  This behavior can be changed using 
    <ahelp name="dmopt">DM options</ahelp>.
    </p>


[binning.dmcopy.sky.fov]
title: Bin Event File to Image With FOV Filtering
requires: acisf06934_000N002_fov1.fits acisf06934N002_evt2.fits
provides: 6934_s3.fits s3.fov
commands : dmcopy "acisf06934_000N002_fov1.fits[ccd_id=7]" s3.fov clob+
           dmcopy "acisf06934N002_evt2.fits[sky=region(s3.fov),ccd_id=7][bin sky=2]" 6934_s3.fits clob+
outfile : 6934_s3.fits
ds9_extras : -scale log -geometry %(geom_sqr)s -zoom 1 -cmap load $ASCDS_CONTRIB/data/heart.lut
pretext : <p>
        Another common spatial filter is to apply the Field of View file (FOV)
        to establish the edges of data within the image.
        The FOV file is a FITS REGION format file that contains at least 1
        row per CCD.  
        </p>
postext : <p>
    In this example we start by running <tt>dmcopy</tt> to select the FOV
    for just CCD_ID=7.
    Then we run <tt>dmcopy</tt> using that file as input to the <tt>region()</tt>
    filter.  The <tt>region<tt> syntax extracts the region from an external
    file.  This same syntax is used with ASCII format region files that users
    may create in <tt>ds9</tt>.
    </p>
    <p>
    The syntax to copy the event file requires 2 separate operations.  
    First the <tt>sky=region(s3.fov)</tt> selects only the events that
    are spatially located within the Field of View.  However, due to the
    way Chandra dithers there will likely be events from neighboring
    CCDs that are imaged within the S3 FOV for some fraction of time
    during the observations.  (Another way to say this is that the
    chips overlap on the SKY due to dither).  Therefore to get only
    the data on S3, we have to add the ccd_id=7 filter.
    Why not just use that filter?  The spatial extent of each chip
    is not stored in the event file.  Without the sky=region() filter, the
    <tt>[bin sky=2]</tt> command would produce a much, much larger 4096x4096
    image (covering the entire image space).  This is why we need to have both.
    The sky=() sets the spatial limits of the data, and the ccd_id filter selects the
    subset of the data to include.
    </p>



[binning.dmcopy.sky.flux]
title : Weighted Binning
requires: acisf06934_000N002_fov1.fits acisf06934N002_evt2.fits s3.fov
provides: fluxed.evt 6934_flux.fits
commands: eff2evt "acisf06934N002_evt2.fits[ccd_id=7,energy=500:3000]" fluxed.evt clob+
          dmcopy "fluxed.evt[sky=region(s3.fov)][bin sky=2;flux]" 6934_flux.fits clob+
outfile : 6934_flux.fits
ds9_extras : -scale log -geometry %(geom_sqr)s -zoom 1 -cmap load $ASCDS_CONTRIB/data/heart.lut
pretext : 
    <p> We do not always bin to accumulate counts.  We can use weighted binning to 
    accumulate other things  like <em>flux</em>.
    </p>
postext : <p>
    In this example we use the <tt>eff2evt</tt> tool to assign a flux 
    to each event on ccd_id=7 in the 0.5 to 3.0 keV range.  Only those events
    are stored in the output <tt>fluxed.evt</tt> file.  
    </p>
    <p>
    We then bin this into an image as we've seen before; except that we
    now add an optional weighting argument.  The <tt>[bin sky=2;flux]</tt>
    tells dmcopy to bin the data into an image, but rather than count
    each row as 1 count, it accumulates the values from the 
    <tt>flux</tt> column in the fluxed event file.
    </p>
    <p>
    This can be a quick way to get a <strong>very</strong> rough
    estimate of the energy flux.  This technique can be 
    very inaccurate when there are low number of counts or if 
    made in very narrow energy bands.
    </p>


[binning.dmnautilus]
title : Adaptive Binning
requires: 6934_s3.fits
provides: 6934_abin.fits 6934_mask.fits
commands : dmnautilus 6934_s3.fits 6934_abin.fits snr=20 outmask=6934_mask.fits clob+
outfile : 6934_mask.fits 6934_abin.fits
ds9_extras : -geometry %(geom_wide)s  -frame 1 -zoom 1 -cmap load $ASCDS_CONTRIB/data/16_ramps.lut -frame 2 -scale log -cmap load $ASCDS_CONTRIB/data/heart.lut 
pretext : <p>
    Usually we work with images that are binned such that all the pixels
    are the same size (and most often, are square).  There are 
    applications where having the data binned on an irregular or adaptive
    grid can be useful.  There are many approaches to compute such a
    grid, in this example we introduce the CIAO tool <tt>dmnautilus</tt>.
    </p>
    <p>
    <tt>dmnautilus</tt> uses a <em>quad-tree</em> algorithm.  It works by taking 
    the image and dividing it
    into 4 approximately equal sub-images.  It computes the signal-to-noise (SNR) 
    for each of the sub-images.  If the SNR is above the desired threshold, 
    then it further subdivides that sub-image in four.  If the SNR is 
    below the threshold, then the process stops for that sub-image tree.
    The result is a grid where each cell ("pixel") will have at most
    a SNR equal to the input threshold.
    </p>
posttext : <p> 
    The image on the Left shows the grid that <tt>dmnautilus</tt> computed, the
    <tt>6934_mask.fits</tt> output file.  Each of the cells in the grid
    has an upper limit SNR=20 (400 counts) -- single pixel cells that 
    could not be subdivided further can exceed this limit.    
    </p>
    <p>
    The image on the Right shows the data with that binning applied.  The 
    boundary of the cluster emission is more easily identified.
    </p>


[binning.dmradar]
title : Adaptive Binning (Polar Coordinates)
requires: 6934_s3.fits
provides: 6934_rbin.fits 6934_rmask.fits
commands : dmradar 6934_s3.fits 6934_rbin.fits snr=20 xcenter=4033.7 ycenter=3956.8 method=0 shape=pie rinner=5 router=500 outmaskfile=6934_rmask.fits clob+
outfile : 6934_rmask.fits 6934_rbin.fits
ds9_extras : -geometry %(geom_wide)s  -frame 1 -zoom 1 -cmap load $ASCDS_CONTRIB/data/16_ramps.lut -frame 2 -scale log -cmap load $ASCDS_CONTRIB/data/heart.lut 
pretext : <p>
    <tt>dmradar</tt> is the polar equivalent of <tt>dmnautilus</tt>. 
    Rather than subdivide the image in X and Y, <tt>dmradar</tt> divides
    the image in Radius and Angle.  This can provide a more natural 
    binning for circular or elliptically shaped emission. 
    </p>
posttext : <p> 
    The image on the Left shows the grid that <tt>dmradar</tt> computed, the
    <tt>6934_rmask.fits</tt> output file.  Each of the pie wedged in the grid
    has an upper limit SNR=20 (400 counts).
    </p>
    <p>
    The image on the Right shows the data with that binning applied.  The 
    boundary of the cluster emission is more easily identified.
    </p>


[binning.dmmaskbin.contour]
title : Contour Map Based Binning
requires: 6934_s3.fits 6934_s3.contour.map
provides: 6934_cbin.fits
commands : dmmaskbin 6934_s3.fits 6934_s3.contour.map 6934_cbin.fits clob+
outfile : 6934_s3.contour.map 6934_cbin.fits 
ds9_extras : -geometry %(geom_wide)s -frame 1 -scale linear -cmap load $ASCDS_CONTRIB/data/16_ramps.lut -frame 2 -scale log -cmap load $ASCDS_CONTRIB/data/heart.lut
pretext : <p>
    The <cxclink href="#binning.dmnautilus">dmnautilus example above</cxclink> shows
    one example of an irregular, adaptive binning algorithm.  There 
    are several other commonly used adaptive binning algorithms 
    in the community:  
    <extlink href="http://adsabs.harvard.edu/abs/2006MNRAS.368..497D">Weighted Voronoi 
    Tessellation</extlink> and 
    <extlink href="http://adsabs.harvard.edu/abs/2006MNRAS.371..829S">Contour Binning
    </extlink>
    are probably the most common two.
    </p>
    <p>
    In this example we introduce the <tt>dmmaskbin</tt> tool that takes as input 
    a traditional counts (or flux) image along with a pixel-map image 
    (which pixels belong to which group) and uses those to create the 
    binned image.
    </p>
posttext: <p>
    In this example we have a input map (Left), <tt>6934_s3.contour.map</tt> .  
    The pixel value indicates to which group the pixel location belongs.    
    </p>
    <p>
    Right:  The output image, <tt>6934_cbin.fits</tt> with a contour mapping binning applied.
    The sum of the pixel values in each group from the input counts image 
    have been normalized by the size of the group and 
    that average value replicated in each pixel in the group in the output image.
    </p>



[binning.dmmaskbin.hardness]
title : Map Based Binning: Hardness Ratio Map
requires: acisf00214N003_evt2.fits acisf00214_000N003_fov1.fits 
provides: cas_a.fits cas_a_bin.fits cas_a_broad.map soft.fits hard.fits hardness.map
commands : 
    dmcopy "acisf00214N003_evt2.fits[sky=region(acisf00214_000N003_fov1.fits[ccd_id=7]),energy=500:7000]" cas_a.fits clob+
    dmnautilus "cas_a.fits[bin sky=2]" cas_a_bin.fits snr=20 outmask=cas_a_broad.map clob+
    dmmaskbin "cas_a.fits[energy=500:1500][bin sky=2]" cas_a_broad.map soft.fits  clob+
    dmmaskbin "cas_a.fits[energy=1500:7000][bin sky=2]" cas_a_broad.map hard.fits  clob+
    dmimgcalc soft.fits,hard.fits none hardness.map op="imgout=((img2-img1)/(img2+img1))" clob+
outfile : hardness.map
ds9_extras : -geometry %(geom_sqr)s -zoom 1 -cmap load $ASCDS_CONTRIB/data/004-phase.lut -cmap invert yes -scale limits -1 1 -view colorbar yes
pretext : <p>
    Based on the <cxclink href="#binning.dmnautilus">above</cxclink> 
    <cxclink href="#binning.dmmaskbin.hex">two</cxclink>
    examples we can now create a more useful example:  Creating a map of the
    hardness ratio.  For simplicity we define the hardness ratio, <em>R</em>, as
    </p>
    <math>
    <latex> \mathcal{R} = \frac{H-S}{H+S}</latex>
    <name>hardness ratio</name>
    <text> R = (H-S)/(H+S)</text>
    </math>

    <p>Where <tt>H</tt> is the number of counts in the hard (high) energy band
    and <tt>S</tt> is the number of counts in the soft (low) energy band. 
    So a hardness ratio approaching 1.0 is a region dominated by
    hard X-ray emission, and values approaching -1.0 are dominated by
    soft emission.
    </p>
    
posttext : <p>
    In this example we take the event file for CasA and apply the spatial
    binning and energy filtering we saw in the earlier examples.  
    </p>
    <p>
    We then run <tt>dmnautilus</tt> on the <em>broad</em> band, ie 
    combine hard+soft bands, to create a grid where we have 
    a combined SNR limit of 20 (ie a limit of 400 counts).
    </p>
    <p>
    We then use this map to create an image of the soft band
    and hard band counts.
    </p>
    <p>
    And the finally we combine those two images using the equation
    above to compute the hardness ratio map.
    </p>
    <p>
    Since we have selected the bins to include roughly 400 counts each,
    the statistical error in this map is low.
    </p>
    <p>
    We can clearly see from this map the hard emission in the Western
    part of the remnant. (North is towards the top of the image).
    </p>


[binning.arbitrary]
title: Binning Arbitrary Axes
requires: cas_a.fits cas_a_broad.map 
provides: cas_a.mapped.evt cas_a.spectra.img
commands:
    dmimgpick cas_a.fits cas_a_broad.map cas_a.mapped.evt method=closest clob+
    dmcopy "cas_a.mapped.evt[bin cas_a_broad_map=1:4957:1,pi=1:1024:1]" cas_a.spectra.img clob+
outfile: cas_a.spectra.img
ds9_extras: -geometry %(geom_sqr)s -pan to 2200 230 physical -scale log -cmap b 
pretext:
    <p>
    So far all the binning example have been of data in sky coordinates.
    However, we can bin data on any column in the input table.
    </p>
    <p>
    In this example we will show a quick way to generate thousands of spectra 
    using the data <cxclink href="#binning.dmmaskbin.hardness">from
    the hardness ratio example</cxclink>.    
    </p>

posttext:
    <p>
    This thread starts by using <tt>dmimgpick</tt> to add a new
    column to the event file.  The new column is called <tt>cas_a_broad_map</tt>.
    The tool looks up the sky position for each event and then
    uses the <tt>closest</tt> value in the map file to 
    populate the new column.
    </p>
    <p>
    Next we use <tt>dmcopy</tt> to create an image but not in
    sky coordinates.  In this example the X-axis is the value of 
    the <tt>cas_a_broad_map</tt> column; ie the group ID.
    The Y-axis is binned on <tt>pi</tt>, which is the 
    observed energy channel.
    </p>
    <p>
    The results:  We now have an image where each column is 
    the spectrum for different parts of the sky.  The image
    above shows just a small segment of the total image zoomed 
    into a region where we can clearly see the change in the 
    spectral signature.
    </p>
    <p>
    Note: This type of spectrum is not immediately useful with CIAO, 
    as we do not have the appropriate response files (ARF and RMF), 
    nor do we have the information we need to account for background
    (including area scaling information).
    </p>


[binning.hexgrid]
title : <new/> Alternative binning: hexagonal grid
requires : 6934_s3.fits
provides : 
commands : hexgrid "6934_s3.fits[sky=region(s3.fov)][opt full]" hex.map clob+ sidelen=10 
    map2reg hex.map hex.reg clob+
    dmmaskbin 6934_s3.fits hex.map"[opt type=i4]" 6934_s3.hex10.fits clob+
outfile : hex.map 6934_s3.hex10.fits
ds9_extras : -geometry %(geom_wide)s  -frame 1 -zoom 1 -linear -cmap load $ASCDS_CONTRIB/data/005-random.lut -frame 2 -scale log -cmap load $ASCDS_CONTRIB/data/heart.lut -region hex.reg
pretext : <p>
    Typically we bin images into square (or more rarely rectangular) pixels
    which approximates the physical geometry of the detector elements (ie
    physical pixels on a CCD). The hexgrid tool allows users to create a 
    hexagonal grid to bin the data.  Why hexagonal?  It turns out that a
    hexagon is the highest order regular polygon (equal length sides) that
    can be used to uniformly tile a 2D plane.  As such, it's the closest
    approximation to a circle; and since the PSF is generally circular
    (or at least elliptical), it may be a closer match to observed
    sources.
    </p>
    <p>
    The hexgrid tool creates a grid of hexagons, with equal side lengths.
    The output map file is an image whose pixel values identify with
    hexagonal group each (square) pixel belongs to.    
    </p>

posttext : <p>
    In this example we created a hexagonal grid where each hexagon 
    is has a side length equal to 10 pixels.  The input image was
    filtered with the field-of-view file so that the tool knows where
    the edge of the detector is and leaves those pixels ungrouped
    (map value equal to 0).  The map file is shown in the left-hand
    side of the image.  For the color map we have chosen a random
    set of colors to help highlight the different map ID values.
    </p>
    <p>
    The output map output is then run through the map2reg script to
    create a region file from the map grid; one region is created for 
    each map ID value found in the input map file. Note: since
    the map ID values are not necessarily continous nor do they 
    necessarily start at 1, the row number (not component value) 
    in the region file may not correspond to the map ID value in 
    the input file.  This file can be used to easily display the map
    grid as is shown in the right-hand side image.
    </p>
    <p>
    As is shown in other Gallery examples, the dmmaskbin tool is then used
    to apply the map file (unfortunately the terms "mask" and "map" are
    sometimes used interchangeably) to the original counts image which
    is what is display in the right-hand side image.
    </p>


[binning.vtbin]
title : <new/> Alternative binning: Voronoi tessellation 
requires : 6934_s3.fits
provides : 
commands : aconvolve 6934_s3.fits 6934_s3_sm.fits "lib:gaus(2,5,1,3,3)" method=slide edge=const const=0 clob+
    vtbin 6934_s3_sm.fits"[sky=region(s3.fov)][opt full]" vt.map clob+
    map2reg vt.map vt.reg clob+
    dmmaskbin 6934_s3.fits vt.map"[opt type=i4]" 6934_s3.vt.fits clob+
outfile : vt.map 6934_s3.vt.fits
ds9_extras : -geometry %(geom_wide)s  -frame 1 -zoom 1 -linear -cmap load $ASCDS_CONTRIB/data/005-random.lut -frame 2 -scale log -cmap load $ASCDS_CONTRIB/data/heart.lut -region vt.reg
pretext : <p>
    Another alternative binning technique is to create a grid based on 
    a <extlink href="https://en.wikipedia.org/wiki/Voronoi_diagram">Voronoi Tessellation</extlink>
    of points. The key feature of the Voronoi tessellation is that each cell
    is a convex hull that encloses each point.  By default, the
    vtbin tool selects the set of points that represents the local maxia 
    in the image. Since we are working with low count data, we want to
    avoid many spurious "1 count" kind of local maxima caused by 
    random fluctuation so this technique works best when the image is
    smoothed. 
    </p>
posttext : <p>In the left hand frame we see the map created by vtbin.
    As with the hexgrid example, the pixel values represent the map ID
    for each region; the color map is a set of random colors to show the
    different regions.  The right hand frame shows the output image
    after the map file has been applied to the original input image
    using the dmmaskbin tool with the region file created by map2reg
    overlaid.     
    </p>
    <p>
    The choice of the initial central points is the key to this 
    algorithm.  The default is to use the local maxima however 
    users can supply their own set of points which is used by the
    <tt>centroid_map</tt> script.
    </p>

[binning.centroid_map]
title : <new/> Alternative binning: centroid map
requires : 6934_s3.fits
provides : 
commands : aconvolve 6934_s3.fits 6934_s3_sm.fits "lib:gaus(2,5,1,3,3)" method=slide edge=const const=0 clob+
    centroid_map 6934_s3_sm.fits"[sky=region(s3.fov)][opt full]" centroid.map numiter=10 clob+
    map2reg centroid.map centroid.reg clob+
    dmmaskbin 6934_s3.fits centroid.map"[opt type=i4]" 6934_s3.centroid.fits clob+
outfile : centroid.map 6934_s3.centroid.fits
ds9_extras : -geometry %(geom_wide)s  -frame 1 -zoom 1 -linear -cmap load $ASCDS_CONTRIB/data/005-random.lut -frame 2 -scale log -cmap load $ASCDS_CONTRIB/data/heart.lut -region centroid.reg
pretext : <p>
    The <tt>vtbin</tt> output can contain highly irregular shapes,
    though adhering to the condition that each is a convex polygon. 
    The <tt>centroid_map</tt> script takes this a step further.  It runs
    <tt>vtbin</tt> to generate an initial set of polygon regions.  It 
    then computes the centroid of the events in each polygon and then
    uses those centroids as input to <tt>vtbin</tt> to compute a new
    set of polygon regions.  This process is repeated a specified number
    of time.  [Theoretically this algorithm would converge so that the 
    centroids would not shift between iterations, but it does so somewhat
    slowly especially at the edges of the data.]
    </p>
    <p>
        The end result is that the output map file generally has much
        more uniform, generally hexagonal shapes. 
    </p>

posttext : <p> 
    This is similar to the <tt>vtbin</tt> example showing the map file
    on the left and the binned image on the right.  The polygons are now
    more uniform in size and spacing.  For very bright sources, the
    polgyons can become very small; users can use the <tt>scale</tt>
    parameter to select different pixel scaling when computing the 
    centroid which will lessen the impact of bright pixels.
    </p>

[binning.pathfinder]
title : <new/> Alternative binning: steepest ascent with pathfinder
requires : acisf04396_broad_thresh.img
provides : 
commands : aconvolve "acisf04396_broad_thresh.img[bin sky=2]" orion.img "lib:gaus(2,5,5,2,2)" clob+
    pathfinder orion.img pathfinder.map minval=1.0 clob+
    map2reg pathfinder.map pathfinder.reg clob+
    dmmaskbin orion.img pathfinder.map"[opt type=i4]" orion.pf.fits clob+
outfile : pathfinder.map orion.pf.fits 
ds9_extras : -geometry %(geom_wide)s  -frame 1 -zoom 1 -linear -cmap load $ASCDS_CONTRIB/data/005-random.lut -frame 2 -scale log -cmap load $ASCDS_CONTRIB/data/heart.lut -region pathfinder.reg
pretext : <p>
    The <tt>dmimgblob</tt> tool creates a map file by identifying 
    clusters of connected pixels that share a side and assigning
    each separate cluster to a separate group. The <tt>pathfinder</tt>
    tool is somewhat similar but instead of grouping all pixels together it creates
    groups by following the steepest gradient from one pixel to its
    neighbors until it finds a local maxima.  All pixels whose 
    steepest ascent gradient that reach the same maxima are grouped
    together.  This has the advantage that it can separate nearby point
    sources.  This tool is better suited for grouping images with 
    many point (or point-like) sources.  It also works best when 
    the input image is smoothed so that it can find the steepest
    gradient without needing to worry about statistical noise.
    </p>
posttext : <p> 
    In this example of the star forming region in Orion, there are many
    individual point sources and with diffuse emission in the center.
    The algorithm is able to separate many of the individual stars based
    on the gradient searching algorithm.  The left image shows the map file
    with a random color map applied.  The right image shows the output
    by binning the original image with the map file.
    </p>
    <p>
    The amount of smoothing can have significant impact on the algorithm.
    Using an adaptive smoothing tool like <tt>dmimgadapt</tt> or <tt>csmooth</tt>
    may help to provide even better source separation. Subtracting the background
    may also help to resolve all the point sources embedded in the 
    extended emission.
    </p>
    

[binning.mkregmap]
title : <new/> Alternative binning: stack of regions with mkregmap
requires : 6934_s3.fits
provides : 
commands : 
    dmellipse 6934_s3.fits ell.fits frac="lgrid(0.1:0.96:0.05)" step=100 clob+
    mkregmap 6934_s3_sm.fits ell.fits"[#row=igrid(1:18:1)]" region.map clob+
    dmmaskbin 6934_s3.fits region.map"[opt type=i4]" 6934_s3.region.fits clob+
outfile : region.map 6934_s3.region.fits
ds9_extras : -geometry %(geom_wide)s  -frame 1 -zoom 1 -linear -cmap load $ASCDS_CONTRIB/data/005-random.lut -frame 2 -scale log -cmap load $ASCDS_CONTRIB/data/heart.lut -region ell.fits
pretext : <p>
    Another way to group data is with a <ahelp name="stack"/> of regions;
    that is use a set of arbitrary regions to define each of the map IDs.
    The regions can be uniformly created using the <tt>pgrid()</tt> or
    <tt>rgrid()</tt> stack syntax, an arbitray list of regions provided
    using the <tt>@filename</tt> syntax, or as shown in this example a
    set of automatically created contour regions created by the 
    <tt>dmellipse</tt> tool.
    </p>
    <p>
        In this example we create a set of elliptical contours that 
        enclose 5%%, 10%%, 15%%, ... up to 95%% of the total counts
        in the image. We then create a map file using the <tt>mkregmap</tt>
        script.  The stack of regions is specified using the
        <tt>igrid()</tt> syntax.
    </p>

posttext : <p>
    The map file (left image) created from the <tt>mkregmap</tt> script
    shown with random colors.  The right image shows the map file applied
    to the original image.  Since the region files are actually input
    to the script there is not need to use <tt>map2reg</tt> to create them;
    we can just directly overlay the contours on the binned image.
    </p>
    <p>
    Question: How did we select the number "18" in the <tt>igrid(1:18:1)</tt>
    syntax?  Answer:
    </p>

    <screen>
    unix%% dmlist ell.fits counts
    18
    </screen>


#~ [binning.merge_too_small]
#~ title : <new/> Alternative binning : merge small regions
#~ requires : 6934_s3.fits
#~ provides : 
#~ commands : hexgrid "6934_s3.fits[sky=region(s3.fov)][opt full]" hex.map clob+ sidelen=10 
    #~ merge_too_small hex.map hex_min50cts.map imgfile=6934_s3.fits method=counts minval=50 clob+
    #~ map2reg hex_min50cts.map hex_min50cts.reg clob+
    #~ dmmaskbin 6934_s3.fits hex_min50cts.map"[opt type=i4]" 6934_s3.hex_min50cts10.fits clob+

#~ outfile : hex_min50cts.map 6934_s3.hex_min50cts10.fits
#~ ds9_extras : -geometry %(geom_wide)s  -frame 1 -zoom 1 -linear -cmap load $ASCDS_CONTRIB/data/005-random.lut -frame 2 -scale log -cmap load $ASCDS_CONTRIB/data/heart.lut -region hex_min50cts.reg
#~ pretext : <p>
    #~ </p>
#~ posttext : <p> 
    #~ </p>

[smooth.aconvolve.gaus]
title : Smooth Image with Gaussian using FFT
requires : 635.img
provides: 635_gsm.img
commands : aconvolve %(requires)s %(provides)s kernelspec='lib:gaus(2,5,1,3,3)' clobber=yes
outfile : %(provides)s
ds9_extras : -scale log -geometry %(geom_sqr)s -zoom 0.6
pretext : <p>We start by simply convolving the input image with a circular, 2D Gaussian</p>
posttext : <p>
    The syntax for the <tt>aconvovle kernelspec</tt> parameter has four parts.
    The <tt>lib</tt> indicates that the smoothing kernel is to be constructed from
    one of the built in library functions.  The <tt>gaus</tt> indicates
    the function to use: a Gaussian.  The values in parentheses are the
    parameters for the Gaussian.  It is a <strong>2</strong>D Gaussian.
    The kernel should extend out to <strong>5</strong> sigma in each
    direction.  The normalization is <strong>1</strong> (arbitrary here as the
    default is to recompute a normalization so that the volume under 
    the kernel is 1).  The final two parameter are the Gaussian sigma terms
    for the X and Y axes.  This example does not include the optional fourth 
    part of the kernelspec -- the location of the center of the smoothing 
    kernel.   
    </p>
    <p>
    Based on this description, we see that this specifies that the 
    data be smoothed by a 2D Gaussian with sigma=3.0 in both X and Y (ie, 
    circularly symmetric) out to a radius of 5*sigma 
    </p>


[smooth.aconvolve.box]
title : Smooth with rectangular box with sliding cell
requires: cas_a.spectra.img
provides: cas_a.spectra.sm_img
commands : aconvolve %(requires)s %(provides)s kernelspec="lib:box(2,1,1,10)" method=slide edge=const clob+
outfile : %(provides)s
ds9_extras : -geometry %(geom_sqr)s -pan to 2200 230 physical -scale log -cmap sls 
pretext : <p> 
    The <tt>aconvolve</tt> tool allows for smoothing kernels of arbitrary
    size.  It also is not restricted to just smoothing images of the sky.
    </p>
posttext : <p>
    In this example, we take the image created in the
    <cxclink href="binning.html#binning.arbitrary">Arbitrary Binning</cxclink>
    example where the X-axis is the region ID number and the Y-axis
    is the Energy.  That image is smoothed with a 2D rectangular box that
    is only 1 pixel wide (X-axis) but 10 pixels long (Y-axis). 
    </p>
    



[smooth.aconvolve.txt]
title : Smooth with Arbitrary Text Kernel
requires : 635_gaus.img 
provides : 635_text.img
commands : aconvolve %(requires)s %(provides)s kernelspec="txt:((-1,-1,-1),(-1,8,-1),(-1,-1,-1))" method=slide norm=none edge=const clob+
outfile : %(provides)s
ds9_extras : -geometry %(geom_sqr)s -zoom 0.6 -scale limits -5 5 -cmap load $ASCDS_CONTRIB/data/heart.lut
pretext : <p>Sometimes it is useful to convolve with a simple, short array of numbers.  
    For example a Laplace edge detector is given by a 3x3 matrix.</p>
posttext : <p>
    In this example a version of the Laplace edge detection kernel is used by
    specifying a set of kernel values using the text, <tt>txt</tt> token.
    The values are given in nested parentheses, going from left-to-right, the values represent the
    bottom left pixel (first value), bottom middle pixel (2nd value), through the
    upper right pixel (9th value).   
    </p>
    <p>
    Unlike the previous examples we also have set the normalization parameter
    <tt>norm=none</tt>.  This is because the sum of the pixels in the 
    kernel is 0; so leaving the normalization at its default value would
    results in pixel values set to <tt>NaN</tt>.
    </p>


[smooth.aconvolve.file]
title : Smooth with Image File
requires: 15403.img 
provides: 15403.psf 15403_file.img
commands: arfcorr infile=%(requires)s outfile=15403.psf region='circle(32814.5,32638.5,100)' x=32814.5 y=32638.5 energy=1.0 mode=h clob+
          aconvolve %(requires)s 15403_file.img kernelspec="file:15403.psf" clob+
outfile : %(requires)s %(provides)s
ds9_extras : -geometry %(geom_wide)s -tile mode column -frame 1 -zoom 2 -scale log -cmap bb -frame 2 -zoom 2 -scale log -cmap bb -frame 3 -zoom 2 -scale log -cmap bb 
pretext: <p>The <tt>aconvolve</tt> tool can also convolve two images together 
    using the <tt>kernelspec=file</tt> option.
    </p>
posttext: <p>
    In this example we use the <tt>arfcorr</tt> tool to create a quick,
    low fidelity, estimate of the Chandra PSF.  The resulting image is 
    saved in the file <tt>15403.psf</tt>.   This PSF is shown in the center
    frame.
    </p>
    <p>
    We then use that image with <tt>aconvolve</tt> as the convolution kernel.
    The input image (shown on the left) is convolved with the PSF (center)
    to produce the output on the right.
    </p>
    <p>
    Note: the input image and the PSF do not need to be the same 
    size (MxN number of pixels); the PSF image can be smaller than the
    input image.  However, the images must have the same resolution (pixel size)
    and tangent point.
    </p>

        
[smooth.aconvolve.3d]
title : Smoothing 3D Image
requires: 06540_evt.fits
provides: cube.fits smcube.fits 
commands : dmcopy "%(requires)s[(chipx,chipy)=box(8003.5,8137.5,512,512,0)][bin chipx=::2,chipy=::2,time=::#50]" outfile=cube.fits clob+
           aconvolve cube.fits smcube.fits "txt:(((8)),((4)),((2)),((1)))" pad+ clob+
outfile : -3d smcube.fits
ds9_extras : -zoom 1.5 -geometry 500x800 -scale log -view buttons yes -view info yes -3d az 60 -3d el 30 -frame delete 1 -sleep 5
pretext : <p><tt>aconvolve</tt> supports multi-dimension images.  This example shows a 
    3D image (cube) of a point source
    shown in chip coordinates.  Since Chandra dithers during the observation, 
    the point source
    moves across the detector versus time, which is the 3rd dimension.</p>
posttext : <p>
    The first step is to create the input data cube.  Here an HRC event file is 
    filtered on the <tt>chip</tt> coordinates and then binned into a cube.
    The X and Y axes are the chipx and chipy values binned by 2, and 
    the third axis is time binned into 50 bins.
    </p>
    <p>
    This cube is input into <tt>aconvolve</tt>.  
    The convolution kernel used here acts like a delta function in the X and Y directions, and has
    an exponential decay along the Z (3rd/time) axis. 
    The Lissajous pattern can be seen as the source  dithers across the
    detector.
    </p>
    


[smooth.csmooth]
title : Adaptive Smoothing with csmooth 
requires: 635.img
provides: 635.img 635_csm.img 635_sig.img 635_scl.img
commands : csmooth infile=%(requires)s outfile=635_csm.img outsig=635_sig.img outscl=635_scl.img sigmin=3 sigmax=5 sclmax=45 clob+ mode=hl
outfile : 635_csm.img
ds9_extras : -geometry %(geom_sqr)s -zoom 0.6 -scale log -scale limits 0 500  -cmap load $ASCDS_CONTRIB/data/purple4.lut
pretext : <p>
    <tt>aconvolve</tt> does a linear smoothing.  It smooths each pixel in the
    input with the same smoothing kernel.  This works very well when 
    all the interesting features in the input are approximately the same 
    size and amplitude.  However, when there are different size features 
    (eg sources) with different amplitudes, a single linear convolution
    may be inadequate.    
    </p>
    <p>
    There are various adaptive smoothing techniques.  They differ in
    performance; how smoothing scales are selected; figure of merit used 
    to know when data are sufficiently smoothed (ie number of counts); etc.
    </p>
    <p>
    CIAO includes the <tt>csmooth</tt> tool.  This is an
    implementation of Harald Ebeling's 
    <extlink href="http://adsabs.harvard.edu/abs/2006MNRAS.368...65E">
    <tt>asmooth</tt> algorithm</extlink>.
    Using the default parameter settings, this algorithm
    smooths the data until the signal-to-noise in each pixel is between 
    the input limits.  It estimates the background from an annulus
    around each pixel; the size is based on the size of the kernel radius.
    </p>
    
posttext : 
    <p>
    <tt>csmooth</tt> is fairly simple to run.  It outputs the smoothed
    image as well as images that record the smoothing scale and the significance
    at each pixel location.
    </p>
    <p>
    Users should be careful about how they use the output image.  The 
    flux in the image is not preserved (a local background has been 
    subtracted.)  There may also be some unphysical structure that
    emerges if there is significant structure in the background. 
    </p>


[smooth.dmimgadapt.gaus]
title : Adaptive Smoothing with dmimgadapt
requires: 635.img
provides: 635_adapt.img
commands : dmimgadapt %(requires)s out=%(provides)s min=1 max=45 num=45 radscal=log fun=gaus counts=25 verb=3 clob+
outfile : %(provides)s
ds9_extras :  -geometry %(geom_sqr)s -zoom 0.6 -scale log -scale limits 0 500  -cmap load $ASCDS_CONTRIB/data/purple4.lut
pretext : <p>
    CIAO also provides the <ahelp name="dmimgadapt" tt="1"/> tools
    which does preserve flux.  However, it does not estimate nor use
    a background in any way.  
    </p>
    <p>
    <tt>dmimgadapt</tt> may be a faster choice depending on the number of 
    scales used.  It also provides more choices in convolution kernels
    which can also greatly increase the speed.
    </p>

posttext:
    <p>
    This <tt>dmimgadapt</tt> output is a direct comparison to the
    <cxclink href="#smooth.csmooth"><tt>csmooth</tt></cxclink> example
    above.  Both use a Gaussian convolution kernel to get 
    approximately 5-sigma, ie 25 counts.
    </p>
    <p>
    It's worth highlighting that the <tt>dmimgadapt</tt> tool knows about the 
    filters which have been applied to the input file (aka the file's 
    data-subspace).  This is why the off-chip pixels appear white in 
    this image -- they are actually <tt>NaN</tt>, whereas <tt>csmooth</tt>
    does not know about off-chip pixels, so the same area is filled with
    the value 0 (shown as black).
    </p>



[smooth.dmimgadapt.cone]
title : Adaptive smoothing with cone shaped kernel
requires: 635.img
provides: 635_adapt_cone.img
commands: dmimgadapt %(requires)s out=%(provides)s min=1 max=45 num=100 radscal=log fun=cone counts=16 verb=3 clob+
outfile : %(provides)s
ds9_extras : -geometry %(geom_sqr)s -zoom 0.6 -scale log -scale limits 0 500  -cmap load $ASCDS_CONTRIB/data/purple4.lut
pretext : <p>
    While using a Gaussian is the most natural choice, it may not be the best
    option to start with.  By definition, a Gaussian has infinite support (is 
    non-zero everywhere). However, beyond some limit, the amplitude of the 
    Gaussian is negligible.  Most algorithms make an arbitrary cutoff,
    usually as a function of FWHM or sigma.  Even so, the size of the
    Gaussian kernel may be quite large; leading to longer program runtimes.    
    </p>
    <p>
    <tt>dmimgadapt</tt> has several other smoothing kernel options which 
    have finite support (identically 0 beyond some limit) and yet still
    retain the general shape of a Gaussian.  Choosing one of these kernels
    can greatly reduce the program's runtime, which can be especially
    useful when doing exploratory analysis trying to determine the range
    of other input parameters to use.    
    </p>
posttext : <p>
    This example shows <tt>dmimgadapt</tt> using the circular <tt>cone</tt>
    shaped kernel. This example uses more smoothing kernels 
    than the <cxclink href="#smooth.dmimgadapt.gaus">previous example</cxclink>;
    and yet because the cone is easier to compute and has a finite base, the 
    <tt>dmimgadapt</tt> program runs much faster.
    </p>
    <p>
    Visually this image is nearly identical to the previous example.  
    Since selecting the set of smoothing kernel scales is often an
    iterative task, we can use the <tt>cone</tt> kernel to 
    quickly optimize those parameters first and then run again 
    using <tt>gaus</tt> to produce the final product.
    </p>


[smooth.dmimgadapt.tophat]
title : Circle With Minimum Number of Counts
requires: 214.img
provides: 214_adapt.img min_100cts.map
commands : dmimgadapt %(requires)s out=214_adapt.img min=1 max=20 num=20 radscal=linear fun=tophat counts=100 verb=3 radfile=min_100cts.map clob+
outfile : min_100cts.map
ds9_extras : -geometry %(geom_sqr)s -zoom 1 -linear -cmap load $ASCDS_CONTRIB/data/16_ramps.lut -view colorbar yes
pretext : 
    <p>
    The primary output from <tt>dmimgadapt</tt> is usually the smoothed image.  However, it
    also provides a map with the size of the smoothing kernel radius 
    as well as the SNR and normalization.
    </p>
    <p>
    The radius map can be very useful for various types of analysis.  Consider the
    case of doing spectral fitting where we require a minimum number of
    counts to get reliable fit results.  We may need to know the size 
    of a circle centered at each pixel location that encloses, for example, at least
    100 counts.  This is easy to get using <tt>dmimgadapt</tt>.
    </p> 
posttext : <p>The image shown is the <tt>min_100cts.map</tt> file.
    Note that units of the radii are in logical pixels, so if an image is binned &gt; 1, which is the 
    case here, you want to be sure to take that into account when using this file.
    </p>
    <p>
    See also the <threadlink name="ttt_mincounts"/> thread.
    </p>


[smooth.ggm]
title : Gaussian Gradient Magnitude
requires: abell496_broad_thresh.img
provides: abell496_gaus10.img abell496_ggm.img abell496_grad.img
commands : aconvolve abell496_broad_thresh.img abell496_gaus10.img "lib:gaus(2,5,5,10,10)" meth=fft clob+
    aconvolve abell496_gaus10.img abell496_grad.img "txt:((0,1,0),(1,-4,1),(0,1,0))" metho=fft clob+ norm=none
    dmimgcalc abell496_grad.img none abell496_ggm.img op="imgout=(abs(img1)*sqrt(2.0))" clob+
outfile : abell496_broad_thresh.img abell496_ggm.img
ds9_extras : -geometry %(geom_wide)s -frame 1 -scale log -pan to 4065 3890 physical -cmap load $ASCDS_CONTRIB/data/gem-256.lut -frame 2 -scale linear -pan to 4065 3890 physical -cmap load $ASCDS_CONTRIB/data/iman.lut -view colorbar on -colorbar vertical
pretext : 
  <p>
  The <em>Gaussian Gradient Magnitude</em>  algorithm 
  is <extlink href="http://adsabs.harvard.edu/abs/2016MNRAS.461..684W">becoming 
  increasingly popular in astronomy image processing</extlink>.  
  The derivative of a Gaussian is an effective edge detector 
  which suppresses high-spatial frequencies, most often associated 
  with the background.
  </p>
  <p>
    We can make use of the convolution identity:
  </p>

  <math><name>gradient</name>
    <latex> I \ast \nabla h = \nabla (I \ast h)</latex>
    <text> I * dh = d(I*h)</text>
  </math>
  <p>
    where <tt>I</tt> is the input image and <tt>h</tt> is a
    Gaussian.  This means that rather than trying to compute the
    partial derivatives of a Gaussian; we only need to 
    convolve the image with a Gaussian, and then compute the
    image gradient.  
    </p>
    
    <p>
    The gradient of an image can be estimated by convolving it
    with a specially constructed convolution kernel; for example the
    Laplace kernel =  <tt>((0,1,0),(1,-4,1),(0,1,0))</tt>
  </p>
  <p>
    As shown here, the <em>GGM</em> is then easy to compute 
    by running <tt>aconvolve</tt> twice.
    <tt>dmimgcalc</tt> is then used to compute the <em>magnitude</em>
    of the gradient estimator; which here is just the absolute value
    of the gradient (the factor of sqrt(2.0) is included for completeness.) 
  </p>

  
posttext :  
    <p>
    In this example we start by smoothing the image with a 10 pixel
    Gaussian, and then estimating the gradient using the Laplace convolution
    kernel.  The result here shows a cavity North of the center of the cluster
    which can then be further analyzed.
    </p>
    <p>
    The choice of the smoothing scale affects the size of detectable features.
    To look for large scale features, a large smoothing scale is required.
    The scale should always be larger than the local PSF size.  Since
    the Chandra PSF varies, some researchers have found innovative ways
    <extlink href="https://github.com/jeremysanders/ggm">to combine GGM 
    from several scales into a single product</extlink>.
    </p>


[smooth.gradient]
title : Directional Gradient Estimators
requires: abell496_gaus10.img
provides: abell496_dx.img abell496_dy.img abell_sobel.mag abell_sobel.ang
commands : aconvolve %(requires)s abell496_dx.img "txt:((1,2,1),(0,0,0),(-1,-2,-1))" meth=fft clob+ norm=none 
           aconvolve %(requires)s abell496_dy.img "txt:((-1,0,1),(-2,0,2),(-1,0,1))" meth=fft clob+ norm=none
           dmimgcalc abell496_dx.img,abell496_dy.img none abell_sobel.mag op="imgout=sqrt((img1*img1)+(img2*img2))" mode=h clob+
           dmimgcalc abell496_dx.img,abell496_dy.img none abell_sobel.ang op="imgout=atan(img2/img1)" mode=h clob+
outfile :  abell_sobel.mag abell_sobel.ang
ds9_extras : -geometry %(geom_wide)s -frame 1 -zoom 0.5 -scale log -cmap h5_bone -frame 2 -zoom 0.5 
pretext : <p>In the <cxclink href="#smooth.ggm">previous example</cxclink> 
    we used the Laplacian gradient estimator.  The nice thing about this
    estimator is that it can be computed with a single convolution.  However, it only contains 
    information about the magnitude of the
    gradient, not the direction.  To get directional information about the gradient, 
    we have to use other gradient estimators.
    </p>
    <p>
    One of the most common gradient estimators is the Sobel kernel.  There is a 
    separate convolution kernel designed to 
    estimate the gradient in the X-direction and in the Y-direction.  These then
    just need to be combined together to get the magnitude and the angle
    of the gradient.
    </p>

posttext : <p>
    In this example we used <tt>aconvolve</tt> to compute the directional gradient in 
    the X-direction and separately in the Y-direction.  Then <tt>dmimgcalc</tt> is used 
    to compute the magnitude (left) and angle (right) of the gradient. The data are the 
    same shown in <cxclink href="#smooth.ggm">the Gaussian Gradient Magnitude example
    </cxclink>, but zoomed out by 50%%. The edge of the cluster emission is easy to identify in 
    the gradient magnitude image (left).  The  gradient direction image (right) is harder to 
    interpret since the angle wraps at 180 degrees, creating an artificial discontinuity.
    </p>
    <p>
    Some other common gradient estimators include:
    </p>
    <table class="ciaotable">
      <tr><th>Name</th><th>X</th><th>Y</th></tr>
      <tr><td>Laplace</td><td><tt>((0,1,0),(1,-4,1),(0,1,0))</tt></td><td><tt>((0,1,0),(1,-4,1),(0,1,0))</tt></td></tr>
      <tr><td>Sobel</td><td><tt>((1,2,1),(0,0,0),(-1,-2,-1))</tt></td><td><tt>((-1,0,1),(-2,0,2),(-1,0,1))</tt></td></tr>
      <tr><td>Roberts</td><td><tt>((1,0),(0,-1))</tt></td><td><tt>((0,1),(-1,0))</tt></td></tr>
      <tr><td>Prewitt</td><td><tt>((1,1,1),(0,0,0),(-1,-1,-1))</tt></td><td><tt>((-1,-1,-1),(0,0,0),(1,1,1))</tt></td></tr>
      <tr><td>Robinson</td><td><tt>((1,1,1),(1,-2,1),(-1,-1,-1))</tt></td><td><tt>((-1,1,1),(-1,-2,1),(-1,1,1))</tt></td></tr>
      <tr><td>Kirsch</td><td><tt>((3,3,3),(3,0,3),(-5,-5,-5))</tt></td><td><tt>((-5,3,3),(-5,0,3),(-5,3,3))</tt></td></tr>
    </table>      



[smooth.unsharp.mask]
title : Unsharp Mask
requires: abell2390.img
provides: abell2390_g3.img abell2390_g30.img abell2390_unsharpmask.img
commands : aconvolve %(requires)s abell2390_g3.img "lib:gaus(2,5,5,3,3)" meth=fft mode=h clob+
           aconvolve %(requires)s abell2390_g30.img "lib:gaus(2,5,5,30,30)" meth=fft mode=h clob+
           dmimgcalc abell2390_g3.img abell2390_g30.img abell2390_unsharpmask.img sub clob+
outfile : abell2390.img abell2390_unsharpmask.img
ds9_extras : -geometry %(geom_wide)s -frame 1 -scale log -cmap load $ASCDS_CONTRIB/data/brain.lut -frame 2 -scale log -cmap load $ASCDS_CONTRIB/data/heart.lut -view colorbar on
pretext :
    <p>
        Unsharp masks have been used by photographers for decades to
        improve the contrast of photographs.  This technique involves
        slightly blurring the original image, inverting it, and adding a 
        scaled version of the inverted, blurred image back to the original image.  The result is
        that edges become more pronounced and visually appealing.
    </p>
    <p>
    Mathematically this looks like:
    </p>

    <math>
      <name>Unsharp</name>
      <latex> U = I - I\ast h</latex>
      <text></text>
    </math>
    <p>
        Where I is the original image, h is the smoothing function (usually a Gaussian), 
        and U is the unsharp mask.  Since a Gaussian is a low pass filter 
        (it tends to preserve large spatial features), by subtracting 
        the smoothed image from itself we are then accentuating small 
        scale features such as edges or boundaries between objects (ie 
        high spatial frequencies).  Unfortunately, this may also adversely
        accentuate the noise.  Therefore, rather than subtract the smoothed
        image from the original, often it is subtracted from a 
        the image smoothed with a different size Gaussian.
    </p>
    <math>
      <name>Unsharp2</name>
      <latex> \hat{U} = I \ast g - I\ast h</latex>
      <text></text>
    </math>
    <p>
        If we require that the spatial scale of <em>g</em> by smaller 
        than <em>h</em>, then what we end up with is a spatial band-pass
        filter that is sensitive to spatial features larger than <em>g</em>
        but smaller than <em>h</em>.  This has the advantage of 
        accentuating spatial features at some spatial scales while
        suppressing the noise.
    </p>

posttext :
    <p>
    The choice of how large to make <em>g</em> compared to <em>h</em>
    is discussed in the literature.  One common 
    convention is to use a factor 10, so if g is a Gaussian with
    a 3 pixel sigma, then h should be a Gaussian with a 30 pixel sigma. 
    <extlink href="http://adsabs.harvard.edu/abs/2010MNRAS.406.1721R">
    Other researchers have used various other values (5 and 20)</extlink>.    
    </p>
    <p>
    Finally, we can rearrange the terms above to get
    </p>
    <math>
      <name>Unsharp3</name>
      <latex> \hat{U} = I \ast (g - h)</latex>
      <text></text>
    </math>

    <p>
    We can then identify the term <em>(g-h)</em> as the 
    difference of Gaussians (DoG).  There has been research
    in this specific topic as the DoG can be used to approximate 
    the Haar (aka Mexican Hat) wavelet.  Given this relationship, some 
    users will select scales at <tt>2<sup>n</sup></tt> radii.
    </p>



[smooth.powerspectrum]
title: Powerspectrum
requires: abell2390_unsharpmask.img
provides: powerspectrum.img
commands:  apowerspectrum abell2390_unsharpmask.img infileimag=none outfile=powerspectrum.img clob+ center+
outfile: powerspectrum.img
ds9_extras: -scale asinh -cmap b -zoom 2
pretext: <p> In the <cxclink href="#smooth.unsharp.mask">previous example</cxclink> we 
    talked about the unsharp mask as a band-pass filter, we can
    see that by looking at the power spectrum (the magnitude of the Fourier transform) 
    of the output.</p>
posttext: <p>
    In this example the power spectrum has been centered such that the 
    middle of the image represents the lowest spatial frequencies (ie 
    the "flat" background) and the highest frequencies are at the 
    edge of the image.  
    </p>
    <p>
    What we see here is an annulus with little power at high
    frequencies due to the 3 pixel Gaussian filter and littler power
    at low frequencies due to the subtraction of the 30 pixel Gaussian
    smoothed image.  This annulus is the frequency band-pass represented
    in the unsharp mask filtered image.
    </p>


[smooth.deconvolve.arestore]
title: Deconvolution: arestore
requires: hrcf10578N003_evt2.fits pcadf370196659N002_asol1.fits 
provides: ar_lac_projrays.fits ar_lac.psf ar_lac.img ar_lac.deconvolve
commands: 
    simulate_psf hrcf10578N003_evt2.fits ar_lac ra=332.1699988 dec=45.7422877 monoenergy=1.0 flux=1.0e-3 numiter=10 minsize=256 rand=5678 mode=h
    get_sky_limits ar_lac.psf 
    dmcopy "hrcf10578N003_evt2.fits[bin X=16150.5:16406.5:#256,Y=16288.5:16544.5:#256]" ar_lac.img clob+
    arestore ar_lac.img ar_lac.psf ar_lac.deconvolve numiter=250 clob+
outfile: ar_lac.img ar_lac.psf ar_lac.deconvolve 
ds9_extras: -geometry %(geom_wide)s -frame 1 -scale log -zoom 4 -cmap load $ASCDS_CONTRIB/data/yellow1.lut -frame 2 -scale log -zoom 4 -cmap load $ASCDS_CONTRIB/data/green7.lut -frame 3 -scale log -zoom 4 -cmap load $ASCDS_CONTRIB/data/brown.lut -tile mode column 
pretext: <p>
    Blind deconvolution techniques also rely on convolution.  In 
    the Richardson-Lucy deconvolution technique, available in the
    <tt>arestore</tt> tool, the image is repeatedly convovled with the PSF
    and then subtracted from itself.  The effect is 
    similar to the unsharp mask being applied repeatedly.  
    </p>

posttext: <p>  
    In this example we used the <tt>simulate_psf</tt> script to run MARX to
    simulate the PSF at the location of ArLac (center image).
    We then used the <tt>get_sky_limits</tt> script to get the limits used
    to bin the PSF image and use that with <tt>dmcopy</tt> to make the image
    of the data (left image).  Finally, we used <tt>arestore</tt> to
    perform the Lucy-Richardson deconvolution technique with 250 iterations
    for the deconvolved image (right image).
    </p>
    <p>
    There appears to be excess flux North of the source.  While it may be
    tempting to think that this is some extended source emission, there
    are several factors to consider such as the energy used in the PSF 
    simulation and the existence of a known PSF artifact, which
    can be located using the following command
    </p>

    <div class='examplecode'>
    <screen>
    <ahelp name="make_psf_asymmetry_region"/> ar_lac.img anomaly.reg x=16277.5 y=16416.1 format=ds9 clob+
    </screen></div>
    <p>
    and loading the region onto the deconvolved image.
    </p>


[detect.wavdetect]
title : Source Detect Regions: wavdetect
requires: acisf00578_s3_broad.img  acisf00578_s3_broad.psfmap acisf00578_s3_broad.expmap   
provides: wav.src wav.cell wav.recon wav.bkg
commands:  pset wavdetect infile=acisf00578_s3_broad.img 
           pset wavdetect outfile=wav.src 
           pset wavdetect psffile=acisf00578_s3_broad.psfmap 
           pset wavdetect expfile=acisf00578_s3_broad.expmap 
           pset wavdetect scellfile=wav.cell 
           pset wavdetect imagefile=wav.recon 
           pset wavdetect defnbkgfile=wav.bkg 
           pset wavdetect scales="1.4 2 4 8 12 16" 
           pset wavdetect clobber=yes
           wavdetect mode=h
outfile : acisf00578_s3_broad.img
ds9_extras : -geometry %(geom_sqr)s -region wav.src -scale log -block 2 -cmap grey -smooth -regions select all -regions width 3 -region select none
pretext : 
    <p><tt>wavdetect</tt> is the most popular CIAO source detection tool.
    It detects sources by convolving the input image with a 
    Haar wavelet (aka Mexican Hat wavelet).  The negative part of the 
    outer annulus provides a natural local background subtraction and
    the Gaussian like central peak acts like a matched-filter.
    </p>
posttext :
    <p>
        The output source list from <tt>wavdetect</tt> is a FITS region file that
        can be directly displayed with ds9. The ellipses show the size
        of the detected source.
    </p>    
    <p>
        It is important to remember that the output from <tt>wavdetect</tt>
        are candidate source detections based on the inputs provided.  Users
        should carefully scrutinize the output list.  Also remember that
        <tt>wavdetect</tt> is not a photometric tool.  While it does
        provide an estimate of the net source counts, users will want to
        use more advanced tools such as <ahelp name="srcflux" tt="1"/> 
        to determine fluxes.
    </p>


[detect.celldetect]
title : Source Detect Regions: celldetect
requires: acisf00578_s3_broad.img acisf00578_s3_broad.expmap acisf00578_s3_broad.psfmap
provides: cell.src
commands: celldetect acisf00578_s3_broad.img cell.src psffile=acisf00578_s3_broad.psfmap expstk=acisf00578_s3_broad.expmap clob+
outfile : acisf00578_s3_broad.img
ds9_extras : -geometry %(geom_sqr)s -region cell.src -scale log -block 2 -cmap grey -smooth -regions select all -regions width 3 -region select none
pretext : 
    <p>
    <tt>celldetect</tt> is a classic sliding-cell detection algorithm.  
    It computes the SNR for pixel values inside a square compared to 
    the local background sampled from a 1 pixel outer box-annulus.  The
    cell size is adjusted to match the size of the PSF making it
    optimized for detection of point sources.    
    </p>

posttext :
    <p>
    The <tt>celldetect</tt> output is similar to the <tt>wavdetect</tt> output; however, some
    bright, off-axis sources are missed.  This may be due to the default 
    SNR <tt>thresh=3</tt> or may be due to the sources being sufficiently
    large compared to the PSF calibration.
    </p>
    <p>
    Since <tt>celldetect</tt> runs so quickly, it is easy for users to experiment
    with different parameters settings.
    </p>
    


[detect.vtpdetect]
title : Source Detect Regions: vtpdetect
requires: acisf00578_s3_broad.img acisf00578_s3_broad.expmap   
provides: vtp.src
commands: vtpdetect acisf00578_s3_broad.img outfile=vtp.src expfile=acisf00578_s3_broad.expmap clob+ mode=h
outfile : acisf00578_s3_broad.img
ds9_extras : -geometry %(geom_sqr)s -region vtp.src"[src_region]" -scale log -block 2 -cmap grey -smooth -regions select all -regions width 3 -region select none
pretext : 
    <p>
    Both <tt>celldetect</tt> and <tt>wavdetect</tt> work by looking for sources of certain
    spatial sizes (<tt>celldetect</tt> cell size or <tt>wavdetect</tt> wavelet scales).
    The <tt>vtpdetect</tt> tool is completely different.  It works by
    computing the Voronoi Tessellation of the input image.  
    The area of each cell is then used to compute a surface brightness 
    density histogram (counts per area).  This histogram is compared to 
    the expected histogram for a flat Poisson background.  
    A source threshold is established from where these curves diverge; 
    those cells are then grouped together to create sources.
    Since the algorithm doesn't make any assumptions about a source's
    size or morphology, it can detect arbitrary, extended objects.
    </p>

posttext :
    <p>
    The <tt>vtpdetect</tt> output source list contains two FITS extensions.  The
    first block contains source ellipses and properties very similar to
    <tt>celldetect</tt> and <tt>wavdetect</tt>.   The ellipses are computed from the
    second order moments of the data and are representative of the 
    source size. The second block contains the actual polygons
    based on the tessellation.    
    </p>
    <p>
    As this example shows, <tt>vtpdetect</tt> easily detects the extended 
    emission in this dataset.  The source polygon in this case is 
    very complicated.  Not only is the exterior outline very irregular, but 
    the polygon actually has holes in which are shown as excluded regions (red
    slash through them).
    </p>
    <p>
    It can be useful to display these polygons, especially if the 
    first block contains thin/narrow ellipses.
    </p>




[detect.get_src_region]
title : Pseudo detect: get_src_region
requires: acisf00578_s3_broad.img
provides: gsr.src acisf00578_s3.fov
commands: 
    dmimghull acisf00578_s3_broad.img acisf00578_s3.fov clob+
    get_src_region "acisf00578_s3_broad.img[sky=region(acisf00578_s3.fov)][bin sky=4]" outfile=gsr.src invert+ clob+ mode=h
outfile : acisf00578_s3_broad.img
ds9_extras : -geometry %(geom_sqr)s -region gsr.src -scale log -block 2 -cmap grey -smooth 
pretext : 
    <p>
    <tt>get_src_region</tt>  works by computing the 
    histogram of the pixel values in the input image, 
    using the mean and standard deviation of this histogram to
    set a source pixel threshold, and then grouping all the 
    source pixels together.      
    </p>
    <p>
    The unusual thing about this tool is how it groups source pixels
    together.  Rather than trying to identify sources as sources, it 
    just identifies regions where the pixels are above the 
    background.  It uses a series of rectangles to identify these
    regions without ever trying to associate the pixels with any specific 
    source.
    </p>
    <p>
    This tool can be used to quickly exclude sources from the background
    (or could for example be used to exclude point sources on top of
    extended emission).
    </p>

posttext : 
    <p>
    Since <tt>get_src_region</tt> computes a histogram of the pixels in the 
    image, we need to be sure that we let it know which pixels 
    in the image are exposed.  So the first thing we do in this
    example is use <tt>dmimghull</tt> to create a 
    pseudo field-of-view (FOV) region file.  This is simply a convex polygon
    that encloses all the non-zero pixels in the image.  </p>

    <p>
    Now when
    we filter with region, the <tt>get_src_region</tt> tool will know
    that the pixel values equal to zero in the corners of the image 
    should not be included in this histogram (and therefore will not
    skew the results).
    </p>
    <p>
    In this example we inverted the region logic, <tt>invert+</tt>, 
    which outputs <em>included</em> rectangles.  The default is to output 
    a region where the rectangles are excluded.
    </p>



[detect.dmimgblob]
title: Connected pixels: dmimgblob
requires: acisf00578_s3_broad.img
provides: acisf00578.gsm acisf00578.bkg acisf00578.net_img blobs.img
commands:
    aconvolve acisf00578_s3_broad.img acisf00578.gsm "lib:gaus(2,5,5,3,3)" meth=fft clob+
    dmimgfilt acisf00578.gsm acisf00578.bkg median "annulus(0,0,20,22)" clob+
    dmimgcalc acisf00578.gsm acisf00578.bkg acisf00578.net_img sub clob+
    dmimgblob acisf00578.net_img blobs.img thresh=0.1 src+ clob+
outfile: blobs.img acisf00578_s3_broad.img
ds9_extras : -geometry %(geom_wide)s -frame 1 -nan black -zoom 0.5 -cmap load  $ASCDS_CONTRIB/data/005-random.lut  -frame 2 -scale log -zoom 0.5 -cmap grey -smooth  -mask mark range -mask range 0.1 9999 -mask color green -mask transparency 10 -mask blobs.img -frame 1 -view colorbar yes
pretext:
    <p>
    It is also possible to construct your own source detection algorithm using
    individual CIAO tools.  What all the source detection algorithms basically
    do is group together pixels with flux above the background.  The 
    details are in how the background is determine and where to 
    set the source threshold.    
    </p>
    <p>
    This example shows a simple, home-grown, source detection algorithm.
    </p>


posttext:
    <p>
    First, the input image is smoothed with a 3-pixel Gaussian using <tt>aconvolve</tt>. 
     This 
    not only suppresses noise, but also works as a matched-filter.  We only
    need to remember that <em>convolution</em> and <em>correlation</em>
    are the same when working with real-valued, symmetrical convolution kernels.
    Instead of thinking of this as a smoothed image, we 
    can also accurately describe this <tt>aconvolve</tt> output 
    as the correlation of the input with a 3-pixel Gaussian which
    emphasizes sources at that same spatial extent.
    </p>
    <p>
     Next we need an estimate of the background.  We use
     the <tt>dmimgfilt</tt> <em>median ring</em> technique described in the 
     <threadlink name="estimatebg"/> thread which estimates the
     background from an median image values in an annulus around each pixel.
    </p>
    <p>
      <tt>dmimgcalc</tt> is then used to subtract the background.  
      Since the background was estimated from the same image, 
      there is no need to do any renormalization. 
    </p>
    <p>
        Finally, <tt>dmimgblob</tt> is used to identify groups of pixels
        above the threshold.  In this example, we selected <tt>thresh=0.1</tt>
        which is 0.1 counts/pixel above the estimated background.
    </p>
    <p>
        The <tt>dmimgblob</tt> output is an image whose pixel values identify which
        group each pixel belongs to.  (Left) shows the blob ID numbers.  Each
        set of connected pixels gets its own ID which have been randomly color
        coded.  (Right) shows the counts data with the blobs overlaid as
        a mask. 
    </p>


[regions.dmcontour.single]
title :  Single contour
requires: a1664.img
provides: a1664.asm a1664_0.75_cntr.reg
commands: 
     dmimgadapt a1664.img a1664.asm cone 1 20 40  linear 100 clob+ 
     dmcontour a1664.asm 0.75 a1664_0.75_cntr.reg clob+
outfile : a1664.asm
ds9_extras : -scale log -geometry %(geom_sqr)s -region a1664_0.75_cntr.reg -cmap load $ASCDS_CONTRIB/data/heart.lut
pretext : 
    <p>
    CIAO has several other tools to create regions automatically from
    the input image beyond those shown in the 
    <cxclink href="detect.html">detect tools</cxclink> gallery.
    </p>
    <p>
    One common task is to draw contours.  This can be done with the
    <tt>dmcontour</tt> tool.
    </p>

posttext : 
    <p>
    The image input to <tt>dmcontour</tt> should be smoothed to avoid getting thousands 
    of small regions around individual single-count pixels. 
    <tt>dmimgadapt</tt> is use here to smooth the image of
    Abell 1664 using a variable size cone; requiring at least 100 
    counts under the smoothing kernel.
    </p>

    <p>
    <tt>dmcontour</tt> is then used to create regions.  A single contour
    is created at level=0.75 counts.
    </p>
    <p>
        As this example shows, there are several small regions that are 
        excluded from within the main contour; as well as several other 
        smaller contour regions outside the primary emission.  The
        <tt>dmcontour</tt> output is a FITS region composed of polygons; 
        the regions are constructed 
        such that the pixel values greater than the contour level
        are included in the polygon.
    </p>


[regions.dmcontour.stack]
title :  Multiple contours
requires: a1664.asm
provides: a1664_stk_cntr.reg
commands: dmcontour %(requires)s  "0.5,0.75,1.0,1.5,2.0,5,12,25" %(provides)s clob+
outfile : %(requires)s
ds9_extras : -scale log -geometry %(geom_sqr)s -region %(provides)s -cmap load $ASCDS_CONTRIB/data/heart.lut
pretext : <p>
    We can also generate multiple contour regions with <tt>dmcontour</tt> 
    similar to the <cxclink href="#regions.dmcontour.single">previous example</cxclink>,

    </p>
posttext : 
    <p>
    Individual contour levels can be extracted
    </p>
    <div class='examplecode'><screen>
    <ahelp name="dmcopy"/> "%(provides)s[contour_level=2.0]" 2.0.reg clob+
    <ahelp name="dmstat"/> "%(requires)s[sky=region(2.0.reg)]" sig- med- cen-
    </screen></div>
    <p>
    or in a single step:
    </p>
    <div class='examplecode'>
    <screen>
    <ahelp name="dmstat"/> "%(requires)s[sky=region(%(provides)s[contour_level=2.0])]" sig- med- cen-
    </screen></div>
    <p>
    Remember, each contour is one or more polygons that includes <strong>all</strong>
    pixel values greater than the contour level.  If you want the pixel values
    between two contour levels, then you would need to filter twice:  once
    to include the lower level, and then a second time to exclude the upper level.
    </p>



[regions.dmimglasso]
title :  Magic Wand Tool: dmimglasso
requires: a1664.asm 
provides: a1664.lasso
commands:  dmimglasso %(requires)s %(provides)s 4126 4008 0.75 INDEF coord=physical clob+ max=100000
outfile : %(requires)s
ds9_extras : -scale log -geometry %(geom_sqr)s -region %(provides)s -cmap load $ASCDS_CONTRIB/data/heart.lut
pretext : 
    <p>
    The <tt>dmcontour</tt> command computes the contour polygons for all 
    pixels in the input image.  As we saw in <cxclink href="#regions.dmcontour.single">first example</cxclink>, 
    it generates polygons around disjoint groups of pixels. 
    The <tt>dmimglasso</tt> tool can be used to create a similar 
    contour-level polygon which restricts the output to those pixels
    which have an unbroken path to the input x,y location.
    </p>
    <p>
    The tool gets its name from the <em>lasso</em> (or <em>magic wand</em>) selection tool available
    in various photo editing packages.
    </p>

posttext : 
    <p>
    In this example <tt>dmimglasso</tt> starts at x=4126, y=4008 and collects
    all the pixels that are greater than 0.75. The output region is
    shown.  Compared to the <cxclink href="#regions.dmcontour.single"><tt>dmcontour</tt>
    example</cxclink>, we see that the two separate, disjoint regions
    are not identified.
    </p> 
    <p>
    A closer inspection of the region will show a "city-block" style contour
    where each line segment is a right angle and fully encloses the pixel.  
    The <tt>dmcontour</tt> output is a polygon with arbitrary angle and location within
    a pixel.  
    </p>
    <p>
    The <tt>max=100000</tt> value is set to ensure that the program can
    recursively compute the needed contour.  This is a hidden parameter used
    to prevent the tool from going into an infinite loop and consuming 
    too much memory.
    </p>


[regions.dmimghull]
title :  Convex Hull
requires: a1664.asm 
provides: a1664_0.75.hull
commands: dmimghull %(requires)s %(provides)s tol=0.75 clob+
outfile : %(requires)s
ds9_extras : -scale log -geometry %(geom_sqr)s -region %(provides)s -cmap load $ASCDS_CONTRIB/data/heart.lut
pretext : 
    <p>
    Both the <tt>dmcontour</tt> and <tt>dmimglasso</tt> polygon outputs 
    have a large number of sides.  Each pixel along the contour
    level edge adds at least one line segment (sometimes two or three). This 
    produces a highly accurate contour, but when used as a filter it
    may result in long CPU runtimes.
    </p>
    <p>
    The <tt>dmimghull</tt> tool computes a simple convex hull (polygon)
    around the above-threshold pixels in the image.  
    </p>


posttext : 
    <p>
    The convex hull shown here bumps out to the west-south-west to include the
    isolated emission which can also be seen in the 
    <cxclink href="#regions.dmcontour.single">above example</cxclink>.
    It also does not have the interior excluded region shown in the
    earlier examples.  But this polygon only has 34 sides compared to the 1,697
    sided polygon created by <tt>dmimglasso</tt>. 
    </p>


[regions.dmellipse.ellipse]
title :  Flux Fraction Ellipse Finding
requires: a1664.asm 
provides: a1664.ellipses
commands: dmellipse %(requires)s %(provides)s "lgrid(0.1:0.96:0.05)" step=100 clob+
outfile : %(requires)s
ds9_extras : -scale log -geometry %(geom_sqr)s -region %(provides)s -cmap load $ASCDS_CONTRIB/data/heart.lut
pretext : 
    <p>
    Another way to automatically generate regions is to create
    a region that encloses a certain fraction of the total flux (or in 
    this case counts).  The <tt>dmellipse</tt> tool does this in a somewhat
    brute force method by guessing the parameters for an ellipse 
    and then increasing or decreasing the size until it finds 
    an ellipse that meets the desired flux fraction.
    </p>
    <p>
    It turns out that this is in general a poorly constrained problem, as there
    are an infinite number of ellipses that can satisfy a simple flux-limit
    constraint.  <tt>dmellipse</tt> imposes additional limits that
    the centroid of the data inside the ellipse is the center of the ellipse
    and that the radii are consistent with the moments.  
    </p>


posttext :
    <p>
    Here we show the dmellipse output for a <ahelp name="stack"/> of
    requested fractions.  The stack is expressed using the <tt>lgrid</tt> (linear grid)
    syntax where we requested fractions going from 0.1 (10%%) to 0.96 (96%%) in
    5%% increments.  We selected 96 rather than 95 so that the 95%% limit would 
    be included.
    </p>
    <p>
    The initial step size is increased because we are making large ellipses.
    This make the tool run much faster.  If working with smaller images
    (eg of the PSF) then a smaller initial step size can be used.
    </p>

    <p>
    In this example the 10%% ellipse is the inner most ellipse.  The 15%% ellipse 
    fully encloses the 10%% ellipse, and so on; however, the center is
    computed separately for each ellipse based on the centroid of the data enclosed by
    that ellipse.  The center of the ellipses drifts slightly as the fraction
    of flux increases.  This is a good indicator that the observed flux
    is not symmetric about a single point.
    </p>
    <p>
    Note:  The gaps in the largest ellipses are an artifact of how
    ds9 draws them.  The actual results are fully enclosed ellipses.
    </p>



[regions.dmellipse.rotbox]
title :  Rectangles instead of Ellipses
requires: a1664.asm 
provides: a1664.rotboxes
commands: dmellipse %(requires)s %(provides)s "lgrid(0.1:0.96:0.05)" shape=rotbox step=100 clob+ 
outfile : %(requires)s
ds9_extras : -scale log -geometry %(geom_sqr)s -region %(provides)s -cmap load $ASCDS_CONTRIB/data/heart.lut
pretext : 
    <p>
    <tt>dmellipse</tt> has the option to use rotated boxes instead of ellipses.
    While this may not be scientifically useful for this particular dataset, it
    does make it easier to see how the algorithm works.
    </p>
posttext :
    <p>
    This example uses <cxclink href="#regions.dmellipse.ellipse">the same parameters as before</cxclink>
    but now we require a rotated
    box to enclose 10%%, 15%%, 20%%, ... 95%% of the counts.  
    </p>
    <p>
    The subtle difference in the rotation angle at each flux level is 
    much easier to see now.    
    </p>
    <p>
    <tt>dmellipse</tt> does have parameters to control the initial
    ellipse or rotbox parameters and also allows the parameters to be
    frozen.
    </p>



[filter.dmcopy.region.inline]
title: Inline Region Filtering
requires: ngc1404.img
provides: ngc1404_inline_region.img 
commands: dmcopy "%(requires)s[sky=circle(3823.5,3959.5,512)]" %(provides)s clob+
outfile: %(provides)s
ds9_extras: -geometry %(geom_sqr)s -scale log -block 2 -cmap load $ASCDS_CONTRIB/data/green7.lut 
pretext: <p>
    <ahelp name="dmregions">Spatial filtering</ahelp> is one of the first operations 
    users typically do.
    CIAO supports all of the basic region shapes:  circle, ellipse, annulus,
    polygon, box, rectangle, pie, and sector.  It supports regions 
    expressed in physical pixels and in World Coordinates.  It also 
    supports full Boolean logic between the shapes: union (or), intersection (and),
    and negation (not).
    </p>

posttext: <p>  
    In this simple example where we filter on the <tt>sky</tt> column. 
    The <tt>sky</tt> column is a <em>virtual, vector</em> column composed of 
    the <tt>x</tt> and <tt>y</tt> columns.  Since the units of the
    <tt>sky</tt> column are in physical <tt>pixels</tt>, the units of the
    region are also interpreted as physical pixels.
    </p>
    <p>
    The region in this example is a single circle that we expressed
    directly as part of the file name's <ahelp name="dmfiltering"><em>virtual 
    file syntax</em></ahelp>.
    </p>
    <p>
    The default behavior of the CXC datamodel is to set pixel values
    outside the region to <tt>0</tt>, and to reduce the size of the  
    image to the bounding box around the region.  Both of these
    can be changed using the <ahelp name="dmopt"><tt>[opt ]</tt></ahelp>
    directive.
    </p>



[filter.dmcopy.region.file]
title: Filter using Region File
requires: ngc1404.img
provides: ngc1404_regfile.img ngc1404_sample.reg 
commands:
    /bin/rm -f ngc1404_sample.reg 
    echo "circle(3266,3999,43.326146)" > ngc1404_sample.reg 
    echo "annulus(3664,4087,49.748272,99.496544)" >> ngc1404_sample.reg 
    echo "ellipse(3818,3969,69.524371,149.01799,339.1735)" >> ngc1404_sample.reg 
    echo "box(3425.1778,3885.9166,132.10846,136.39276,27.855707)" >> ngc1404_sample.reg 
    echo "polygon(3982.0598,3906.9402,4054,4011,4093.9402,3906.9402,4272,3807,4216,3635,3952,3609,3982.0598,3795.0598)" >> ngc1404_sample.reg 
    echo "pie(3844.4911,4169.4991,0,346.40231,34.028978,87.028978)" >> ngc1404_sample.reg 
    echo "rectangle(3436.5,3587.5,3598.5,3729.5)" >> ngc1404_sample.reg 
    dmcopy "%(requires)s[sky=region(ngc1404_sample.reg)]" ngc1404_regfile.img clob+
outfile: ngc1404_regfile.img
ds9_extras : -geometry %(geom_sqr)s -region format ciao -region ngc1404_sample.reg -scale log -block 2 -cmap load $ASCDS_CONTRIB/data/green7.lut 
pretext: <p> 
    More complicated regions are often stored in external region files
    and are read in using the <tt>region()</tt> syntax.
    </p>
    <p>
    CIAO supports the ASCII regions that <tt>ds9</tt> creates in 
    either the native ds9 format or in the CIAO format.  CIAO also
    supports regions in the <cxclink href="/contrib/arots/fits/ascfits.ps">ASC-FITS-REGION format</cxclink>.
    </p>

posttext: 
    <p> This shows a gallery of most of the CIAO shapes that CIAO
    supports. The regions are stored in an ASCII file using 
    the simple CIAO format. </p>
    <p>
    The output image shows the input image filtered with the  
    <em>union</em> of the individual shapes.  This is the default
    logic.  The individual shapes can also be <em>intersected</em>
    and/or <em>negated</em>.
    </p>

    <p>
    The information about the filter is stored in the output file and is 
    used downstream by CIAO in tools such as <ahelp name="dmstat" tt="1"/> and
    <ahelp name="dmextract" tt="1"/>.  You can review the filters by
    looking at the <ahelp name="subspace">file's subspace</ahelp>.
    </p>
    <div class='examplecode'>
    <screen>
    dmlist ngc1404_regfile.img subspace
    </screen>
    </div>
    <p>
    You can get more complicated shapes by inverting regions and by
    using logical and and or.
    </p>
    

[filter.dmcopy.xor]
title: Filter Logic: XOR (Exclusive OR)
requires: ngc1404.img
provides: ngc1404_xor.img ngc1404_xor.reg 
commands:
    /bin/rm -f ngc1404_xor.reg 
    echo "ellipse(3822.6874,3961.1154,254,52,140)" > ngc1404_xor.reg 
    echo "-ellipse(3822.6874,3961.1154,254,52,40)" >> ngc1404_xor.reg 
    echo "ellipse(3822.6874,3961.1154,254,52,40)" >> ngc1404_xor.reg 
    echo "-ellipse(3822.6874,3961.1154,254,52,140)" >> ngc1404_xor.reg 
    dmcopy "%(requires)s[sky=region(ngc1404_xor.reg)][opt full]" ngc1404_xor.img clob+
outfile: ngc1404_xor.img
ds9_extras : -geometry %(geom_sqr)s -region format ciao -region ngc1404_xor.reg -scale log -block 2 -cmap load $ASCDS_CONTRIB/data/green7.lut 
pretext:  <p>
    CIAO regions supports full Boolean logic: and, or, not, operations on
    individual shapes.  This makes CIAO very flexible; but can lead to some
    confusion for new users.
    </p>
    <p>
    One of the most common CIAO questions is how excluded regions are 
    treated.  In some data analysis systems, an excluded shape is
    always implicitly excluded from every/any shape it overlaps.  This is not
    how CIAO interprets excluded shapes.  Given the full Boolean logic operations
    available in CIAO, a shape must explicitly be excluded from any/every
    overlapping shape as required.
    </p>
    <p>
    This use of explicit logic leads to much greater flexibility in how
    regions are interpreted.  As an example, consider the <em>Exclusive OR</em>
    operation:
    </p>

    <math>
    <latex> A \oplus B = A\bar{B} + B\bar{A}
    </latex>
    <name>XOR</name>
    <text>A^B = A*!B + B*!A</text>
    </math>

    <p>
    In astronomy terms, this might be used to create a region that 
    includes the flux from two regions, but not the flux from
    the overlapping region.   This operation is difficult to
    replicate in some systems; however, using the relation shown 
    above, it is simple to perform with CIAO region filters.    
    </p>
    

posttext:  
    <p>This is the combination of 4 ellipses which have been
    constructed to create the exclusive OR (XOR) operation.  The
    output retains the data that is in either ellipse, but not 
    both of them.  The ellipses are constructed with the same
    radii and center; the angle (measured from the +X axis) 
    is different.  
    </p>

    <p>
    In CIAO, the minus operator, <tt>-</tt>, is actually short hand
    for two separate operations:  <tt>and</tt> and <tt>not</tt>.  So
    </p>
    <math>
    <latex>A-B = A*!B = A*\bar{B}</latex>
    <name>minus</name>
    <text>A-B=A*!B</text>
    </math>

    <p>
    Using this we can see how the above filter logic works.
    The data from the first ellipse is included, except for the 
    region which overlaps the second ellipse.  That is then union-ed (OR)
    with the data from the second ellipse, excluded for the region 
    that overlaps the first ellipse.
    </p>

    <p>
    This type of logic is not available in some other software systems.
    By removing the excluded regions, always from every overlapping 
    shape, the result of this region file would be that all pixels
    would be excluded.
    </p>
    <p>
    The figure above shows all four ellipses; however, since they overlap
    only two are visible.  Also, since the ellipses are excluded, the 
    red-hash line ds9 uses to indicate negation is seen.  ds9 
    can only display the individual shapes, not the logic used to
    combine those shapes.
    </p>
    <p>
    Note the use of <tt>[opt full]</tt>.  The default behavior is to shrink the
    image to a bounding box around the filtered region, but using the <tt>full</tt>
    option the original image size is retained.
    </p>


[filter.dmcopy.region.bounds]
title: Bounding Box
requires: ngc1404.img ngc1404_sample.reg 
provides: ngc1404_bounds.img 
commands:
    dmcopy "ngc1404.img[sky=bounds(region(ngc1404_sample.reg))]" ngc1404_bounds.img clob+
outfile: ngc1404_bounds.img
ds9_extras : -geometry %(geom_sqr)s -region format ciao -region ngc1404_sample.reg -scale log -block 2 -zoom 0.95 -cmap load $ASCDS_CONTRIB/data/green7.lut 
pretext: <p> 
    There are various use-cases where we only need to know the 
    size and extent of the region being used.  These include
    pre-filtering the dataset to make subsequent filtering faster;
    getting the size so that other products (exposure maps, PSF maps) can be 
    made on the same grid; determining the set of CCDs being imaged; etc.
    </p>
    <p>
    The <tt>bounds()</tt> syntax can be used with any region specifier to
    get a bounding box around the region.  The bounding box is always
    rectangular and non-rotated.  It only considers the region, not the data.
    </p>

posttext: <p> 
    This is an example of using <tt>bounds()</tt> using the region file 
    created in 
    <cxclink href="#filter.dmcopy.region.file">the above example</cxclink>.
    The individual shapes have not been used to construct the filter logic; 
    rather the size/extent of each shape is used to create an overall
    bounding box around all the shapes in the region file.
    </p>
    <p>
    The output image has been shrunk to the limits of
    the bounding box; unlike in the earlier example, the pixels
    "between" the shapes are included, since the <tt>bounds()</tt> 
    syntax was used.      
    </p>  


[filter.dmimgproject]
title: Row-|Column-wise projection and replication
requires: acisf367640304N001_5E002_img0.fits
provides: bias_projx.tab acisf367640304N001_5E002_offset.img
commands:
    dmimgproject acisf367640304N001_5E002_img0.fits outfile=bias_projx.tab axis=x clob+
    dmimgreproject "bias_projx.tab[cols x,mean]" acisf367640304N001_5E002_img0.fits acisf367640304N001_5E002_offset.img method=closest clob+
outfile: acisf367640304N001_5E002_offset.img
ds9_extras: -geometry %(geom_sqr)s -block 2 -cmap load $ASCDS_CONTRIB/data/pastel.lut

pretext:
    <p>
    There are various techniques to determine the background level in an image.
    ACIS raw images, those used on-orbit for event detection,
    have strong column-to-column  variation and significant offsets
    between each of the four readout-nodes.     
    </p>
    <p>
    The ACIS on-orbit <dpguide page="misc" id="bias">bias maps</dpguide>
    are created by taking the average of the pixel values in each 
    column. Only part of the CCD is processed at a time due to the
    memory limits of the camera.
    </p>
    <p>
    We can approximate this column-by-column background determination
    using the <tt>dmimgproject</tt> and <tt>dmimgreproject</tt> tools.
    </p>


posttext:
    <p>
    In this example we first take an ACIS raw image,
    <tt>acisf367640304N001_5E002_img0.fits</tt>, and compute the
    projections onto the X-axis.  This is an image
    in ACIS chip coordinates:  CHIPX goes along the X-axis
    and CHIPY along the Y-axis.  Data are readout along the
    CHIPY direction to one of four amplifier nodes.
    Due to the high dynamic range of pixel values, it is 
    difficult to display this image before background subtraction
    and therefore not shown here.
    </p>
    
    <p>
     Due to the limited
    telemetry bandwidth, ACIS raw images are rarely telemetered to
    the ground.  Usually, events are detected and the raw image buffer
    is flushed.  However, for calibration and health-and-safety
    purposes, the CXC collects raw images from ACIS several times per
    year.  Users must request these files from the archive operations
    group.
    </p>
    <p>
    <tt>dmimgproject</tt> computes several statistics for each column (X-axis)
    or row (Y-axis) including the mean pixel value, median, standard
    deviation, etc.  In this example, to replicate the on-orbit 
    behavior we are going to use the mean value.
    </p>

    <p>
    In the second command, <tt>dmimgreproject</tt> is used to replicate
    the per-column mean value back into each row of the image.  
    The output image shown above.  Each column is a constant value equal 
    to the mean of the pixel values in that column.  The four ACIS readout 
    nodes are clearly visible as is the column-to-column variation
    within each node.
    </p>

    <p>
    The small stripes of data on the far 
    right-hand-side of the image is from the <em>overclock pixels</em>, 
    which are not physically present on the CCD; a full discussion of
    the topic of overclock pixels is beyond the scope of this example.
    </p>


[filter.dmimgthresh.zero]
title: Image Threshold at Zero
requires:  acisf367640304N001_5E002_img0.fits acisf367640304N001_5E002_offset.img
provides: acisf367640304N001_5E002_zero.img acisf367640304N001_5E002_flat_img0.fits
commands:
    dmimgcalc acisf367640304N001_5E002_img0.fits acisf367640304N001_5E002_offset.img acisf367640304N001_5E002_flat_img0.fits sub clob+
    dmimgthresh acisf367640304N001_5E002_flat_img0.fits acisf367640304N001_5E002_zero.img cut=0 value=0 clob+
outfile: acisf367640304N001_5E002_zero.img
ds9_extras: -geometry %(geom_sqr)s -block 2 -cmap load $ASCDS_CONTRIB/data/icool.lut -scale log -scale limits 0 1000
pretext: <p>
    Rather than remove pixels, you may want to replace values in the image.
    One common approach is to set a threshold and to replace values
    less than that threshold to some fixed value.  For example when
    subtracting background, you may want to set any residuals &lt;0
    to 0.
    </p>
posttext:
    <p>
    First, we subtract the <cxclink href="#filter.dmimgproject">output bias map from the
    previous example</cxclink> from the original raw image.  This
    removes all the node-to-node and column-to-column variations 
    present in the raw exposure.
    </p>

    <p>
    Then we apply a threshold where any pixels less than 0 are
    set to 0 using <tt>dmimgthresh</tt>.  This is the image
    shown here.
    </p>
    <p>
    What we see here is a ~10 second exposure on one of the
    front-side illuminated CCDs. The bright features
    are the result of charge liberated from cosmic rays hitting the CCD.
    The cosmic rays hit the CCD at various angles which leads to 
    shapes of the charge trail.  The point of entry is the narrow 
    end of the charge trail.  The charge tail blooms as the cosmic
    ray travels deeper into the Silicon substrate and further away
    from the influence of the charge-collecting gate structure. 
    </p>
    <p>
    There are also some low-amplitude, residual, column-by-column features 
    which are acceptable given the other sources of noise in the image.
    </p>



[filter.dmimgthresh.upper_limit]
title: Image Threshold Upper Limit
requires: acisf367640304N001_5E002_zero.img 
provides: acisf367640304N001_5E002_crater.img
commands:
    dmimgthresh %(requires)s %(provides)s cut=:20 value=0 clob+
outfile: %(provides)s
ds9_extras: -geometry %(geom_sqr)s -block 2 -cmap load $ASCDS_CONTRIB/data/icool.lut -scale log -scale limits 0 1000
pretext: <p>
    This example builds on <cxclink href="#filter.dmimgthresh.zero">the
    previous example</cxclink> which applied a threshold to values
    &lt;0.  Now in this example we want to apply an upper threshold.
    </p>
    <p>
    The bright charge clouds produced by the cosmic rays are 
    transient.  They need to be removed if we intend to use this
    image to compute a mean bias.    
    </p>
    <p>
    There are various ways this can be done.  Again, here 
    we simulate what the ACIS camera does on-orbit and simply apply
    an upper-limit threshold.
    </p>


posttext: <p>
    Here an upper threshold of 20 was applied.  But rather than set
    the pixel values greater than 20 to 20, we instead set them to 0.
    </p>
    <p>
    This is very similar to the on-board algorithm used to compute the
    ACIS bias images used for event detection.  
    </p>
    <p>
    The resulting image shown.  The idea is that anything greater than
    this pre-determined threshold must be a cosmic ray.  Since we
    expect the pixel values to be around zero now that we have removed
    the column-by-column variation, any pixel above a certain 
    threshold is interpreted to be influenced by a cosmic ray 
    charge bloom and the value is replaced with 0.
    </p>
    <p>
    With the bright, central part of the charge clouds removed; only
    the edges remain giving the image a cratered look.
    </p>



[filter.nonlinear.mean.stack]
title: Combine Stack of Images: CR rejection
requires: acisf367640304N001_5E*crater.img
provides: acisf367640304N001_5_bias.img
commands: dmimgfilt "acisf367640304N001_5E*crater.img" acisf367640304N001_5_bias.img mean "point(0,0)"  clob+
outfile: %(provides)s
ds9_extras: -geometry %(geom_sqr)s -block 2 -cmap load $ASCDS_CONTRIB/data/icool.lut -scale log -scale limits 0 1000
pretext: 
    <p>
    If we repeat the <cxclink href="#filter.dmimgthresh.zero">previous</cxclink> 
    <cxclink href="#filter.dmimgthresh.upper_limit">two steps</cxclink>
    with several other ACIS raw frames, we can then combine them together to
    create a final bias map.  
    </p>
    <p>
    The residual column-by-column and cosmic-ray-crater edges can be
    further suppressed by averaging multiple exposures together.
    </p>

posttext:
    <p>
    The previous steps were repeated with the other ACIS raw
    images.  The result is a set of eight images which 
    look similar to 
    <cxclink href="#filter.dmimgthresh.upper_limit">this example</cxclink>,
    each with its own unique pattern of cosmic ray crater edges.    
    </p>

    <p>
    To create the output file, the <tt>dmimgfilt</tt> tool takes the same 
    <tt>point(0,0)</tt> from each of the images in the stack, computes
    the <tt>mean</tt> of those value and stores it in the output image.
    It then moves the point to the next pixel and repeats.
    This stack of input images is specified using the UNIX
    wildcard, <tt>*</tt>, syntax: <tt>acisf367640304N001_5E*crater.img</tt>.
    </p>
    <p>
    The output then is simply the mean value from the same pixel
    taken from each file in the input stack.  The output is scaled the same 
    as the previous examples so we can see that the amplitude of the 
    residual noise has been greatly decreased.  There are still some
    artifacts.
    </p>
    <p>
    Here we chose to use the <tt>mean</tt> to match what is done
    by the ACIS camera on-orbit.  Given the nature of the noise
    and the limited number of data points, using a <tt>median</tt>
    or some type of clipped-mean may provide a flatter bias map.
    </p>





[filter.dmimgfilt.median]
title: Background Estimate: Median Ring
requires: acisf04396_broad_thresh.img
provides: orion.img orion.bkg
commands:
    aconvolve "acisf04396_broad_thresh.img[bin sky=2]" orion.img "lib:gaus(2,5,5,2,2)" clob+
    dmimgfilt orion.img orion.bkg median "annulus(0,0,20,22)" clob+
outfile: orion.img orion.bkg
ds9_extras: -geometry %(geom_wide)s -frame 1 -scale log -scale limits 0 1000 -block 2 -cmap heat -frame 2 -scale log -scale limits 0 1000 -cmap heat -block 2
pretext: 
    <p>
    Non-linear filters can be useful in a variety of ways.  
    The <em>Median Ring</em> technique discussed in the 
    <threadlink name="estimatebg"/> thread 
    is a quick way to get a fairly reliable estimate of 
    image background.    
    </p>

posttext:
    <p>   
    This example shows a simple way to estimate the background by
    computing the median pixel value in an annulus around each
    pixel in the input image.  This process works best when 
    using a smoothed image, since the median of integer values
    is noisy.  
    </p>
    <p>
    The choice of the size of the annulus (ring) should be such that
    its inner radius is larger than the expected source size (ie PSF) 
    and the outer radius is small enough to only sample the local 
    background.
    </p>
    <p>
    We can see in this example that the point sources have been
    effectively removed from the input image and the diffuse emission
    at larger spatial scales has been preserved.
    </p>
    <p>
    This process imparts a low-amplitude, high-spatial frequency
    structure on the output. If that is undesirable, then users
    can simply smooth the output
    </p>
    <div class="examplecode">
    <screen>
    aconvolve orion.bkg orion.sm_bkg "lib:gaus(2,5,5,5,5)" 
    </screen>
    </div>
    
    <p>
    This type of filter can also be considered a type of non-linear 
    smoothing (taking the median rather than the mean or simple
    linear combination of values).  We can see this in the output
    as we see the gaps between the chips have increased -- which 
    can be very important when using this type of image for
    exposure corrections.
    </p>


[filter.dmfilth.poly]
title: Replace pixels: Interpolation
requires: orion.bkg
provides: orion.de orion.outer_de orion.outer.fits orion.outer_de.fits orion.bkg.interp
commands:
    dmimglasso orion.bkg orion.de x=4130 y=4170 lo=0.5 high=INDEF maxdep=100000000 clob+ mode=h
    dmimglasso orion.bkg orion.outer_de x=4130 y=4170 lo=0.4 high=INDEF maxdep=100000000 clob+ mode=h
    dmcopy orion.outer_de"[region][#row=1]" orion.outer_de.fits clob+
    dmcopy orion.de"[region][#row=1]" orion.de.fits clob+
    dmfilth orion.bkg orion_interp.bkg method=POLY src="region(orion.de.fits)" bkg="region(orion.outer_de.fits)" mode=h clob+
outfile: orion_interp.bkg
ds9_extras: -geometry %(geom_sqr)s -scale log -scale limits 0 1000 -cmap heat -block 2 -region orion.outer_de.fits -region color white -region orion.de.fits
pretext: <p>
    Another way to replace the pixel values is to interpolate over
    some region.
    </p>
    <p>
    The <tt>dmfilth</tt>, <em>Fill in the Hole</em>, tool has several
    options to replace pixels values in the image based on 
    a user supplied background region.  Different methods place
    different restrictions on how the target (ie source) and donor (ie background)
    regions have to be created.
    </p>
 
posttext: 
    <p>
    In this example we start by running <tt>dmimglasso</tt> to get a polygon region
    surrounding the diffuse emission in the background from 
    <cxclink href="#filter.dmimgfilt.median">the previous example</cxclink>.

    We actually run <tt>dmimglasso</tt> twice.  Once to get an inner
    polygon, using a higher threshold of 0.5. This is the inner polygon; the
    pixel values inside this region will be filled in.
    Then we run <tt>dmimglasso</tt> again 
    with a lower threshold of 0.4 to generate the outer polygon.  The
    pixel values inside this region (but outside the interior polygon) 
    will be used to compute the coefficients for the two-dimension second-order
    polygon.
    </p>
    <p>
    Next we select only the first row of each of those region files using
    <tt>dmcopy</tt>.
    As we saw in <cxclink href="#regions.dmimglasso">another example</cxclink>
    the <tt>dmimglasso</tt> 
    output may contain interior excluded regions.  For this example we
    only want the outermost region which will be the first one in the
    output file.  
    </p>
    <p>
    Finally we then run <tt>dmfilth</tt> to <em>fill in the hole</em>.
    Using <tt>method=POLY</tt> it takes the pixel values in the background
    region (green polygon) that are not in the source region (white polygon)
    and uses them to do a 2D, second-order polygonal least-squares-fit 
    over the source region.
    </p>


[filter.dmfilth.poisson]
title: Replace Pixels: Random Sample
requires: acisf04396_broad_thresh.img orion.de.fits
provides: orion.poisson_filled.fits
outfile : orion.poisson_filled.fits
commands:
    dmfilth "acisf04396_broad_thresh.img[bin sky=2]" orion.poisson_filled.fits method=POISSON src="region(orion.de.fits)"  bkg="circle(3435.5,4093.5,150)" rand=32 mode=h clob+
ds9_extras: -geometry %(geom_sqr)s -scale log -scale limits 0 1000 -cmap heat -block 2 -region color white -region orion.de.fits -regions command "circle(3435.5,4093.5,150) # background" 
pretext: 
    <p>
      <tt>dmfilth</tt> also has the option to fill in the source
      region with random Poisson noise (background).  
    </p>
posttext:
    <p>
    In this example we take the regions from 
    <cxclink href="#filter.dmfilth.poly">the previous example</cxclink>
    for the diffuse emission region (white curve) and replace the pixel
    values by sampling from a Poisson random variable using a 
    count-rate determined from the events in the background (dashed green)
    region.
    </p>
    <p>
    <tt>dmfilth</tt> requires that the background region must be completely 
    disjoint from the source region when using <tt>method=POISSON</tt>.  
    A co-located annulus is OK as long as there are no pixels at the
    edge which are included in both regions. 
    </p>


[filter.dmimgthresh.expmap]
title: Map Based Threshold
requires: orion.outer_de orion.de orion.img
provides: orion.poly_ring orion.poly_ring.img
commands:
    dmimgcalc orion.outer_de orion.de orion.poly_ring sub clob+
    dmimgthresh orion.img orion.poly_ring.img cut=1 value=INDEF exp=orion.poly_ring clob+
outfile: orion.poly_ring orion.poly_ring.img
ds9_extras: -geometry %(geom_wide)s -frame 1 -zoom 0.5 -frame 2 -nan cornflowerblue -scale log -scale limits 0 1000 -cmap heat -zoom 0.5
pretext:
    <p>
    The <ahelp name="dmimglasso" tt="1"/> output file contains both 
    a REGION extension as well as a pixel mask that identifies which pixels
    are inside the region.  We can use this to help visualize the
    polygon region shown in 
    <cxclink href="#filter.dmfilth.poly">the above example</cxclink>.
    </p>
posttext:
    <p>
    (Left) First we subtract the inner polygon from the outer polygon.  Since they
    both started at the same location, the inner polygon must be entirely
    enclosed within the other polygon.  Since the mask pixel values
    are either 1 (inside the polygon) or 0 (outside), if we subtract
    the inner mask from the outer mask, the polygon annulus 
    that is left behind will be the region that is inside the outer 
    polygon, but not inside the inner polygon.
    </p>
    <p>
    (Right) Next we use the subtracted mask to filter the image using <tt>dmimgthresh</tt>.  
    We set the <tt>expfile</tt> parameter to the mask file name.
    Then we set the threshold so that any pixels less than 1 
    are set to <em>INDEF</em>, which is the special value 
    we use when we want the output pixel values to be <tt>NaN</tt>
    or <tt>BLANK</tt> (depending on the data-type).
    </p>
    <p>
    The final image shows the filtered data using the ds9
    <tt>heat</tt> color map.  Pixel values that are outside the
    filtered region have been set to NaN and are colored blue.
    </p>


#[miscellaneous.dmimgcalc.subtract]
#title: Subtract PSF 
#requires: acisf17128N002_evt2.fits
#provides: 3c15.img 3c15.psf 3c15.residual 
#commands:
#dmcopy "acisf17128N002_evt2.fits[energy=500:7000,sky=circle(4065.2766,4071.5784,72)][bin sky=0.2]" 3c15.img clob+
#arfcorr 3c15.img out=3c15.psf region="circle(4065.2766,4071.5784,72)" x=4064.8 y=4071.8 energy=2.4 arf= mode=h clob+
#dmstat 3c15.img,3c15.psf cen- sig- med- 
#dmimgcalc 3c15.img,3c15.psf none 3c15.residual op="imgout=(img1-((5912/0.9438)*img2))" clob+
#outfile:  3c15.img 3c15.psf 3c15.residual
#ds9_extras: -geometry %(geom_wide)s -tile column -frame 1 -zoom 3 -scale log -cmap load $ASCDS_CONTRIB/data/red2.lut -frame 2 -zoom 3 -scale log -cmap load $ASCDS_CONTRIB/data/blue4.lut -frame 3 -zoom 3 -scale limits -10 10  -cmap load $ASCDS_CONTRIB/data/004-phase.lut
#pretext: 
#<p>
#Given the Poisson nature of Chandra data we do not typically simply 
#just "subtract" the PSF from an image.  This just 
#increases the statistical uncertainty without providing 
#much in the way of quantitative results.  However, with a
#sufficiently accurate model of the PSF, can provide some
#hints about potentially interesting analysis paths.    
#</p>
#posttext: 
#<p>
#(Left) Here we create an image with <tt>dmcopy</tt> enclosing 
#a point-like source with an apparent jet extending to the North-West.
#The question is whether there is any extended emission closer to 
#object.  We can do some preliminary analysis by subtracting
#a model of the PSF. 
#</p>
#<p>
#(Center) While <cxclink href="/chart">ChaRT</cxclink> is the standard,
#and best calibrated PSF model available, it also is not easy to run. 
#The easiest method to generate an approximation of the PSF
#is to use the <tt>arfcorr</tt> tool.  The energy parameter
#was selected based on the mean energy of the events in the region.
#</p>

#<p>    
#(Right) The output from <tt>arfcorr</tt> is normalized to 1.0.  To subtract it from the
#counts data, it has to be scaled.  There are various options in how
#to choose the scaling.  One could use the ratio of the 
#counts in some region.  For simplicity here we  use the ratio of the
#maximum pixel value in each image.  
#Here the pixels colored Red are where the image is greater than
#the PSF, and pixels colored blue are where the PSF is greater than
#the image pixels.    
#</p>


#<p>
#While we can unambiguously identify the jet-like feature to the North-West
#(upper right), there are too many sources of systematic uncertainties with
#this simple PSF model to characterize any extended emission closer to the source.
#It does appear that there is extended emission around the 
#source (emission larger than what the PSF would predict), we need
#to remember that the <tt>arfcorr</tt> output is not a very accurate approximation of the
#true PSF, especially at subpixel resolution.  It is sufficiently 
#accurate at single pixel resolution to determine enclosed counts
#fractions (PSF integrated over some region); however, it lacks
#fidelity as a pixel-by-pixel model.
#</p>
    

[miscellaneous.dmmaskfill]
title: dmmaskfill: paint by number
requires: acisf06934N002_evt2.fits 6934_s3.contour.map
provides: 6934.mapped.evt map.dat mean_energy.dat lookup.tab 6934_s3.contour.map.filled
commands:
    dmimgpick "acisf06934N002_evt2.fits[ccd_id=7,energy=500:3000]" 6934_s3.contour.map 6934.mapped.evt method=closest clob+
    dmlist 6934_s3.contour.map data,clean,array  | grep -v ^# | sort -n | uniq > map.dat
    cat map.dat | xargs -I@ dmstat "6934.mapped.evt[cols energy][contmap=@]" | grep mean | cut -d: -f2 > mean_energy.dat
    dmpaste map.dat"[cols contmap=col1]" mean_energy.dat"[cols energy=col1]" lookup.tab  clob+
    dmmaskfill lookup.tab 6934_s3.contour.map 6934_s3.contour_filled.map clob+
outfile: 6934_s3.contour_filled.map
ds9_extras: -geometry %(geom_sqr)s -scale limits 1200 1400 -linear -cmap load $ASCDS_CONTRIB/data/iman.lut -view colorbar yes
pretext:
    <p>
    Whether making temperature maps, variability maps, or maps of hardness ratios,
    it is often convenient to start your analysis with a map
    that groups pixels together.  Typically these maps have integer
    values where the pixel value identifies group membership.  
    The CIAO tools <ahelp name="dmnautilus" tt="1"/> and 
    <ahelp name="dmimgblob" tt="1"/> both produce such a
    map as part of their outputs.  Examples of
    these can be seen in the 
    <cxclink  href="binning.html#binning.dmnautilus">Binning</cxclink>
    and <cxclink href="detect.html#detect.dmimgblob">Detect</cxclink>
    galleries.  There are various other non-CIAO tools that also
    apply their own grouping scheme and output similar data products.
    </p>
    <p>
    These maps can be use to select data for analysis for each 
    individual region.  Once the analysis is complete -- whether 
    it is computing 
    a temperature, or measure of variability, etc -- it is often 
    helpful to visualize the results by mapping the analysis results back
    to spatial regions from whence they originated.     
    </p>
    <p>
    This is easy to do with the <tt>dmmaskfill</tt> tool.
    </p>
    

posttext:
    <p>
    In this example we are going to compute the mean energy 
    for the events in the Abell 2597 cluster.  We  have used
    an external package to compute a map,
    <tt>6934_s3.contour.map</tt>, 
     where the pixels 
    have been grouped along various flux contours.    
    </p>
    
    <p>
    The first step is to identify which events belong to 
    which region.  This is easy to do with <tt>dmimgpick</tt>.
    This adds a new column to output table which gives the
    map value which is <tt>method=closest</tt> to the
    event location.  In this example the new column is called <tt>CONTMAP</tt>.
    </p>

    <p>
    The next step is make a table which is a list of all the 
    pixel values in the map.  We use <tt>dmlist</tt> with the 
    <tt>data,clean,array</tt> options to generate a list of 
    all the pixel values.  The header line is removed with the
    <tt>grep -v ^#</tt> command.  The values are then sorted
    numerically and the unique values are stored in the file <tt>map.dat</tt>.    
    </p>
    <p>
    The next command then runs the <tt>dmstat</tt> command 
    for each unique map value.
    The UNIX <tt>xargs</tt> command is a very handy utility to 
    use for this kind of looping.  As demonstrated here, xargs takes each 
    line from the <tt>map.dat</tt> file (via standard input),
    and runs the <tt>dmstat</tt> command shown, but replacing the <em>@</em> 
    with the value on each line; eg if the line is '100' then it runs
    the command 
    </p>
    <screen>dmstat "6934.mapped.evt[cols energy][contmap=100]"</screen>
    
    <p>
    The rest of the command then selects the <tt>mean</tt> output 
    value and stores the results in a file called <tt>mean_energy.dat</tt>.
    </p>

    <p>
    We now have one file which contains the map ID number, <tt>map.dat</tt>, 
    and one file which contains the mean energy for the events
    closest to that map ID number, <tt>mean_energy.dat</tt>.  
    Since the CXC Datamodel can read these simple lists as ASCII files, 
    we then just want to combine them together into a single table using 
    the <tt>dmpaste</tt> tool.
    To make things a little more clean, we rename the columns
    on-the-fly to have more descriptive names.
    </p>

    <p>
    The final step then is to create the output image shown
    here by using <tt>dmmaskfill</tt> to replace the map ID 
    number with the mean energy value.
    The output shows a map of the mean energy (in eV, since
    those are the units of the Energy column in the event file).    
    The nature of this <em>cool core</em> cluster 
    <extlink href="http://adsabs.harvard.edu/cgi-bin/nph-abs_connect?bibcode=2005cxo..prop.2023C;2009ApJ...697.1597H;2010MNRAS.405..898O;2010A%%26A...521A..64S;2011MNRAS.410.1797S;2011ApJ...731L..23K;2011PhDT.........4O;2012MNRAS.424.1042T;2012MNRAS.424.1026T;2013MNRAS.429.2727S;2011PhDT........21T;2010A%%26A...513A..37H;2015A%%26A...575A..30S;2015MNRAS.451.3768T;2016A%%26A...585A.130H;2016A%%26A...592A.112H;2016MNRAS.463.3582M;2016ApJS..227...31S">
    is the topic of several papers</extlink>.
    While this is not a <em>temperature</em> map, it does provide a 
    way to do some preliminary analysis with that ultimate goal in mind.        
    </p>



[miscellaneous.dmimglasso.map]
title: Convert mask to polygon
requires: 6934_s3.contour.map
provides: 33.map 33.lasso 33.tag
commands:
    dmimgthresh 6934_s3.contour.map 33.map cut=33:33 value=0 clob+
    dmstat 33.map cen- sig- med- verb=0
    punlearn dmcoords
    pset dmcoords x=` stk_read_num ")dmstat.out_max_loc" 1 echo+`
    pset dmcoords y=` stk_read_num ")dmstat.out_max_loc" 2 echo+`
    dmcoords 33.map op=sky verb=0
    pset dmimglasso xpos=`pget dmcoords logicalx | awk '{print int($1+0.5)}' `
    pset dmimglasso ypos=`pget dmcoords logicaly | awk '{print int($1+0.5)}' `
    dmimglasso 33.map 33.lasso low=33 hi=INDEF coord=logical clob+ mode=h
    echo "32.5 33.5 yellow" > 33.tag
outfile: 6934_s3.contour.map
ds9_extras: -geometry %(geom_sqr)s -scale log -region width 2 -region 33.lasso -zoom 3 -pan to 4032 3955 physical -cmap tag load 33.tag
pretext:
    <p>
    While working with region maps as shown in 
    <cxclink href="#miscellaneous.dmmaskfill">the other example</cxclink>
    is very convenient, there are times when you may need to 
    convert those mapped pixels into standard CIAO regions
    (typically polygons).  This may be needed for things such
    as computing areas (although there are other
    ways to compute areas using <ahelp name="dmimghist" tt="1"/>) or
    just general compatibility with other tools/packages.
    </p>
    <p>
    In <cxclink href="regions.html#regions.dmimglasso">another example</cxclink>
    we saw how to use <tt>dmimglasso</tt> to create a polygon.  In that
    example we skipped over the critical step of how to determine
    the starting x,y location.  This may be obvious/trivial when running
    things interactively, but when trying to script it can be 
    a little tricky.
    </p>
posttext:
    <p>
    In this example we are going to create a region that encloses map ID <tt>33</tt>
    in the <tt>6934_s3.contour.map</tt> input file.  This ID was 
    selected because it corresponds to pixels that form a pseudo-annulus.
    Therefore, we cannot simply select the center (or centroid) of 
    the image to be the starting point.  <tt>dmimglasso</tt> requires that
    the starting point be inside the region being created.  So we 
    need to identify a pixel (any pixel will do) that is inside the region
    formed from the map with a pixel value equal to 33.    
    </p>
    <p>
    The first <tt>dmimgthresh</tt> uses <tt>cut=33:33</tt>.  The
    cut threshold is implemented such that values strictly less-than 33 
    are set to 0 and values that are strictly greater-than 33 are also 
    set to 0.  This means that only pixels values equal to 33 remain.
    </p>
    <p>
    The next several commands are used to automatically select the
    starting point for <tt>dmimglasso</tt>.  We start by running
    <tt>dmstat</tt>.  In this example, the center/centroid is not
    useful; however, <tt>dmstat</tt> also outputs the <em>location</em>
    of the maximum pixel value: <tt>out_max_loc</tt>.  Since we
    are using the input that has been run through <tt>dmimgthresh</tt>, 
    we know that the maximum pixel value for the map ID is 33, which is where
    we want <tt>dmimglasso</tt> to start.
    </p>
    <p>
    Now while it is tempting to take <tt>dmstat</tt>'s <tt>out_max_loc</tt> value and use that
    directly, users will find that due to the numerical precision of the
    output, this will sometimes fail.  To make this process robust, we
    need to convert the <tt>out_max_loc</tt> location from physical coordinates
    to integer logical coordinates.  This solves the problems with numerical
    precision and avoids issues dealing with needing to know the image bin size.
    </p>
    <p>
    We do this by using the <ahelp name="stk_read_num" tt="1"/> tool 
    to parse the <tt>dmstat</tt> output <ahelp name="parameter">using
    the ")" parameter file redirect syntax</ahelp>.  <tt>dmstat</tt>
    stores the location of the maximum pixel value into the <tt>out_max_loc</tt>
    parameter as a comma separated pair of x,y values.  <tt>stk_read_num</tt>
    is used to read each value: 1 for x, 2 for y.  Those values 
    are <tt>pset</tt> into <tt>dmcoords</tt>' parameter file.
    </p>
    <p>
    Then we run <tt>dmcoords</tt> with <tt>op=sky</tt>, which uses
    the values that were just <tt>pset</tt>.  <tt>dmcoords</tt> converts
    those sky coordinates to various other Chandra coordinate systems, 
    including the logical (image) coordinates we are looking for.    
    </p>
    
    <p>
    <tt>dmcoords</tt> stores the logical coordinates in two parameters:
    <tt>logicalx</tt> and <tt>logicaly</tt>.   These values are 
    real-valued.  We use the UNIX <tt>awk</tt> command convert these to integers 
    by rounding them to the closest pixel.  These are <tt>pset</tt> into the
    <tt>dmimglasso</tt> parameter file.
    </p>
    
    <p>
    Finally, the <tt>dmimglasso</tt> tool is run.  The important
    thing to note is the use here of <tt>coord=logical</tt> to let 
    the tool know that the input coordinate are to be interpreted 
    as image/logical pixels.  
    </p>
    
    <p>
    The final <tt>echo</tt> is used to create a 
    <extlink href="http://ds9.si.edu/doc/new.html">ds9 Color Tag</extlink>
    file which is used to apply a color to range of pixel values.  In this
    case, pixel values between 32.5 and 33.5 will be colored yellow.
    </p>
    <p>
    The image above shows the output region file.  It is composed of two
    polygons.  The inner polygon is excluded from the outer polygon 
    to form the pseudo-annulus we were expecting.  The red-slash indicating
    an excluded region is for the inner polygon.
    The yellow color-tag file has been applied to highlight the 
    pixel values used to create the region.    
    </p>

    
    





[miscellaneous.dmimgfilt.skeleton]
title: Skeletonize 
requires: abell496_ggm.img abell496_broad_thresh.img
provides: ggm_skel_thresh.img ggm_h.img ggm_v.img ggm_skel.img
outfile: ggm_skel_thresh.img abell496_broad_thresh.img
commands:
    dmimgfilt abell496_ggm.img ggm_h.img function=peak mask="box(0,0,1,3)" clob+
    dmimgfilt abell496_ggm.img ggm_v.img function=peak mask="box(0,0,3,1)" clob+
    dmimgfilt ggm_h.img,ggm_v.img ggm_skel.img function=max mask="box(0,0,3,3)" clob+
    dmimgthresh ggm_skel.img - cut=INDEF value=0 | dmimgthresh - ggm_skel_thresh.img cut=0.002 value=0 clob+
ds9_extras: -geometry %(geom_wide)s -frame 1 -pan to 4065 3890 physical -cmap load $ASCDS_CONTRIB/data/green8.lut -frame 2 -scale log -smooth -pan to 4065 3890 physical -cmap load $ASCDS_CONTRIB/data/gem-256.lut -mask color green -mask transparency 0.5 -mask ggm_skel_thresh.img -pan to 4065 3890 physical
pretext:
    <p>
    In this example we take the 
    <cxclink href="smooth.html#smooth.ggm">Gaussian Gradient Magnitude</cxclink>
    output and perform further analysis.  
    </p>
    <p>
    The output from that example shows a sharp edge 
    (large gradient magnitude)  to the South-East
    of the center of the cluster.  We can refine the estimate of the
    location of the edge by applying a <em>skeletonization</em> technique.
    </p>
posttext:
    <p>
    The GGM is the magnitude of the gradient (after being smoothed with a
    Gaussian).  We can define the location of an edge to be 
    where the magnitude of the gradient is maximum.    
    </p>
    <p>
    The first two runs of <tt>dmimgfilt</tt> with <tt>function=peak</tt> 
    decomposes the GGM image into horizontal and vertical edges.
    The <tt>peak</tt> statistic is used to
    search for the local maximum in a vertical (1x3) and horizontal (3x1) box.  
    The <tt>peak</tt> function returns the current pixel value if it is the maximum value
    of the pixels in the mask; if the current pixel is not the local maximum 
    then the output pixel is set to <tt>NaN</tt>.
    </p>
    <p>
    We then combine the horizontal and vertical edges together.
    The <tt>dmimgfilt</tt> tool is used again, but this time with a
    stack of inputs: the horizontal and vertical edges, and 
    now using the <tt>max</tt> function.    The output then
    is the maximum pixel value in a sliding 3x3 box taken from 
    either of the two input files.  If the edge is not detected in
    either input, the output will be NaN.  If the edge is detected 
    horizontally, that value is used.  If the edge is detected
    vertically, that value is used.  If both, then the maximum value
    is used (which in this case will be the same in each dataset). 
    </p>
    <p>
    The output skeleton image then contains either the GGM pixel
    value if that pixel was detected as the local maximum in either the
    horizontal or vertical direction, or NaN if not.  Since the 
    majority of the pixels are not local maxima, most of the output 
    pixels are NaN.
    </p>
    <p>
    We then apply two separate thresholds to the pixel values.
    First, pixel values set to NaN are replaced with 0.  This makes
    displaying the dataset easier.  Then we apply an adhoc lower
    level threshold of 0.002. This value was selected for this
    example dataset based on trial and error to reduce appearance of
    edges due to random background fluctuations. 
    </p>

    <p>
    The image on the left is the skeletonized GGM.  The pixel values
    are equal to the pixel values in the GGM image where the gradient
    magnitude is maximum.  
    </p>
    
    <p>
    The image on the right shows the original data with
    the skeletonized GGM overlaid on top as a 
    <extlink href="http://ds9.si.edu">ds9 mask</extlink>.
    </p>
    
    <p>
    This type of output is not necessarily intended to represent a
    final data product.  It is intended to help assist users in
    locating interesting spatial regions to perform additional
    data analysis.
    
    </p>
    
    



# reproject_image / reproject_image_grid :
# dmimgdist
# dmimgfilt open/close, diolate/eroade

# [histograms]
# dmextract pi, time, radial, weighted
# dmimghist
# pfold
# glvary
# dmtabfilt
# dmimgpick

# [responses]
# asphist
# mkinstmap, various on-offs
# sky2tdet
# mkwarf
# mkarf
# mkacisrmf / rmfimg
# mkgarf(?)
# fov
# mkpsfmap
# limsens
# ?create_bkg_map?
# dmimgpm
# acis_streak_map
# OOT bkg
# dither_region


# eff2evt / mean_energy_map




#[regions.roi]
#title :  Automating region creation 
#commands: 
#outfile : 
#ds9_extras : 
#pretext : 
#posttext :




